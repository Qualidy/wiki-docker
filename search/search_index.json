{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\u00dcbersicht","text":"Video <p>"},{"location":"#docker-schulung","title":"Docker Schulung","text":"<ul> <li> <p>  Einf\u00fchrung in Docker </p> </li> <li> <p>  Installation auf Windows </p> </li> <li> <p>  Container vs. Images </p> </li> <li> <p>  Port Mapping in Docker </p> </li> <li> <p>  Container im Hintergrund ausf\u00fchren </p> </li> <li> <p>  Containerinhalt live bearbeiten </p> </li> <li> <p>  Tagging von Docker-Images </p> </li> <li> <p>  \u00dcbung </p> </li> <li> <p>  Docker Runtimes </p> </li> <li> <p>  Slim- und Alpine-Images </p> </li> <li> <p>  Datenpersistenz in Docker </p> </li> <li> <p>  Eigene Docker-Images erstellen - Einstieg </p> </li> <li> <p>  Hosting </p> </li> <li> <p>  Docker Layers </p> </li> <li> <p>  Eigene Docker-Images erstellen - Erweitert </p> </li> <li> <p>  Docker Compose</p> </li> <li> <p>  Devcontainer</p> </li> </ul>"},{"location":"content/1/","title":"1 Einf\u00fchrung","text":"Erstes GUI \u2013 Label und zwei Buttons <p>Erstelle ein WinForms-Projekt, f\u00fcge ein Label <code>LblAnzeige</code> und zwei Buttons <code>CmdHallo</code>, <code>CmdEnde</code> ein.</p> <ul> <li> <p>Form-Text: \u201eMein erstes Projekt\u201c</p> </li> <li> <p><code>LblAnzeige</code> zun\u00e4chst leer, mit Rahmen (<code>FixedSingle</code>)</p> </li> </ul> \\[ \\frac{10}{12}x \\] Tipp <p>Hier noch ein Tip</p> L\u00f6sung L\u00f6sungsvideo <p> </p> <pre><code>// Eigenschaften per Designer setzen.\n// Optional per Code im Form_Load:\nprivate void Form1_Load(object sender, EventArgs e)\n{\n    this.Text = \"Mein erstes Projekt\";\n    LblAnzeige.Text = \"\";\n    LblAnzeige.BorderStyle = BorderStyle.FixedSingle;\n}\n</code></pre> <pre><code>flowchart TD\n    A[Christmas] --&gt;|Get money| B(Go shopping)\n    B --&gt; C{Let me think}\n    C --&gt;|One| D[Laptop]\n    C --&gt;|Two| E[iPhone]\n    C --&gt;|Three| F[fa:fa-car Car]</code></pre>"},{"location":"content/compose/","title":"Docker Compose","text":"<p>Wenn mit mehreren Dockercontainern gleichzeitig in einem Projekt gearbeitet wird, ist es m\u00f6glich diese gemeinsam zu bauen, indem man das Tool Docker Compose nutzt.</p> <p>Dazu legen wir (unser letztes Beispiel fortf\u00fchrend) im Hauptverzeichnis die Datei <code>docker-compose.yml</code> an:</p> docker-compose.yml<pre><code>services:\n  backend:\n    image: mysite-backend\n    pull_policy: never\n    container_name: todo-backend-container\n    build:\n      context: ./backend\n      dockerfile: dockerfile\n    ports:\n      - 8000:8000\n\n  frontend:\n    image: mysite-frontend\n    pull_policy: never\n    container_name: todo-frontend-container\n    build:\n      context: ./frontend\n      dockerfile: dockerfile\n    ports:\n      - 80:80\n</code></pre> <p>Nun k\u00f6nnen die folgenden Befehle verwendet werden, um alle Container gleichzeitig zu bedienen:</p> Befehl Bedeutung <code>docker compose build</code> Baut alle Images <code>docker compose up</code> Baut alle Container und startet sie. <code>docker compose down</code> Baut f\u00e4hrt alle Container herunter."},{"location":"content/container_background_run/","title":"Container im Hintergrund ausf\u00fchren","text":"<p>Standardm\u00e4\u00dfig l\u00e4uft ein Docker Container im Vordergrund. Das bedeutet, sobald man einen Container startet, bleibt das Terminal \"blockiert\" \u2013 es zeigt die Logausgabe des Containers an, und man kann in diesem Terminalfenster keine weiteren Befehle ausf\u00fchren, solange der Container l\u00e4uft.   Das sieht z.B. so aus:</p> <p></p> <p>Nach dem Start wird sofort die <code>nginx</code>-Logausgabe angezeigt und das Terminal wartet. Man kann den Container dann mit <code>STRG + C</code> schnell beenden. Wenn man m\u00f6chte, dass der Container im Hintergrund l\u00e4uft und das Terminal sofort wieder verf\u00fcgbar ist, kann man den sogenannten Detached Mode aktivieren. Das geschieht mit dem Flag <code>-d</code>:</p> <pre><code>docker run -d -p 8080:80 nginx\n</code></pre> <p>Der Container wird hier wie gewohnt gestartet, aber er l\u00e4uft jetzt im Hintergrund. Das Terminal steht direkt f\u00fcr neue Befehle zur Verf\u00fcgung. Au\u00dferdem wird im Terminal noch eine sogenannte Container-ID ausgegeben:</p> <p></p> <p>Diese lange Zeichenkette ist die ID des gestarteten Containers. Diese ID kann genutzt werden um mit dem Container zu interagieren. Wenn man <code>docker ps</code> ausf\u00fchrt, sieht man genau dieselbe ID in der Spalte \"Container ID\":</p> <p></p> <p>Man muss aber nicht unbedingt die Container-ID nutzen, man kann auch den zuf\u00e4llig erstellten Namen verwenden:</p> <p></p> <p>Diesen Namen k\u00f6nnen wir beim Start des Containers selber festlegen, dazu gibt man den <code>--name</code>-Flag mit. Vorher muss man nat\u00fcrlich den Container beenden, da der Port 8080 bereits verwendet wird, dadurch wird er wieder frei:</p> <pre><code>docker run -d -p 8080:80 --name my-nginx nginx\n</code></pre> <p>Man sieht auch in Docker Desktop unter \"Containers\", alle bisherigen Containers:</p> <p></p> <p>Mithilfe der Container-ID oder des Namens, k\u00f6nnen wir z.B. die Logs des container ansehen:</p> <pre><code>docker logs my-nginx\n</code></pre> <p></p> <p>Oder man klickt in Docker Desktop auf den jeweiligen Container, da sieht man ebenfalls die Logs:</p> <p></p> <p>Man sieht hier auch direkt, dass man in der Lage ist, den Container innerhalb der GUI zu stoppen oder auszuf\u00fchren:</p> <p></p> <p>Zum Stoppen des Container, nutzt man im Terminal in den meisten F\u00e4llen, folgenden Befehl:</p> <pre><code>docker stop my-nginx\n</code></pre> <p>In den Logs des gestoppten Container m\u00fcsste in etwa <code>worker process.... exited with code....</code> stehen. Auch der gr\u00fcne Punkt in der Gui, neben dem Container, ist verschwunden:</p> <p></p> <p>Wir bereits bemerkt, werden die Container nach dem Stoppen nicht gel\u00f6scht. Falls man alle gestoppten Container dauerhaft enrfernen m\u00f6chte, kann man es \u00fcber die GUI machen oder direkt im Terminal mit:</p> <pre><code>docker container prune\n</code></pre> <p></p> <p>Wenn man mit Docker h\u00e4ufig arbeitet, wird man feststellen dass man fr\u00fcher oder sp\u00e4ter viele ungenutzte Container hat. Um genau dieses Problem zu vermeiden, gibt es den <code>--rm</code>-Flag. Dadurch wird der Container automatisch gel\u00f6scht, sobald er beendet wird:</p> <pre><code>docker run -d -p 8080:80 --name my-nginx --rm nginx\n</code></pre> <p></p> <p>Nach dem Stoppen des Container ist er im Docker Desktop, wegen <code>--rm</code>, nicht mehr vorhanden.</p>"},{"location":"content/container_webinhalt_bearbeiten/","title":"Container live bearbeiten","text":"<p>In diesem Beispiel lernst du Schritt f\u00fcr Schritt, wie man einen Nginx-Webserver als Container im Hintergrund startet, sich mit der Shell in diesen Container verbindet und anschlie\u00dfend die Standard-Webseite bearbeitet.  </p>"},{"location":"content/container_webinhalt_bearbeiten/#ablauf","title":"Ablauf","text":"<ol> <li> <p>Container starten:    Mit <pre><code>docker run -d --name web-server -p 8080:80 nginx:1.27.0\n</code></pre>    wird ein Container mit dem Namen <code>web-server</code> im Hintergrund gestartet. Das Image basiert auf der Nginx-Version 1.27.0. Durch <code>-p 8080:80</code> wird der Port 80 des Containers auf Port 8080 des Hostsystems weitergeleitet, sodass der Webserver von au\u00dfen erreichbar ist.  </p> </li> <li> <p>Im Browser \u00f6ffnen:    Wenn du im Browser <code>http://localhost:8080</code> eingibst, sollte die Nginx-Startseite erscheinen. Damit \u00fcberpr\u00fcfst du, ob der Container l\u00e4uft und erreichbar ist.  </p> </li> <li> <p>In den Container einloggen:    Mit <pre><code>docker exec -it web-server sh\n</code></pre>    \u00f6ffnest du eine interaktive Shell innerhalb des Containers. So kannst du direkt mit dem Linux-Dateisystem und den installierten Programmen im Container arbeiten.  </p> </li> <li> <p>Inhalt auflisten:    Mit <pre><code>ls\n</code></pre>    siehst du die Dateien und Verzeichnisse im aktuellen Arbeitsverzeichnis des Containers. Das ist n\u00fctzlich, um dich im Container zu orientieren.  </p> </li> <li> <p>Vim testen:    Wenn du <pre><code>vim\n</code></pre>    eingibst, \u00fcberpr\u00fcfst du, ob der Texteditor Vim im Container installiert ist. Standardm\u00e4\u00dfig ist er bei Nginx-Images meist nicht vorhanden.  </p> </li> <li> <p>Vim installieren:    Falls Vim fehlt, installierst du ihn mit: <pre><code>apt-get update\napt-get install -y vim\n</code></pre>    Der erste Befehl aktualisiert die Paketquellen, der zweite installiert den Editor.  </p> </li> <li> <p>Vim starten und wieder schlie\u00dfen:    Mit <pre><code>vim\n</code></pre>    \u00f6ffnest du den Editor. Mit den folgenden Befehlen kannst du Text einf\u00fcgen, speichern oder abbrechen.  </p> <p>Vim-Grundlagen</p> <ul> <li><code>i</code> \u2192 Einf\u00fcgen starten (Textbearbeitung m\u00f6glich)  </li> <li><code>Esc</code> \u2192 zur\u00fcck in den Normalmodus </li> <li><code>:wq</code> \u2192 speichern und beenden </li> <li><code>:q</code> \u2192 beenden ohne Speichern (falls keine \u00c4nderungen) </li> <li><code>:q!</code> \u2192 erzwingen: beenden ohne Speichern </li> </ul> </li> <li> <p>Standard-Webseite ansehen:    Mit <pre><code>cat /usr/share/nginx/html/index.html\n</code></pre>    kannst du dir den Inhalt der Standard-Webseite von Nginx anzeigen lassen.  </p> </li> <li> <p>Standard-Webseite bearbeiten:    Mit <pre><code>vim /usr/share/nginx/html/index.html\n</code></pre>    \u00f6ffnest du die HTML-Datei im Editor. Hier kannst du eigene \u00c4nderungen vornehmen, z. B. den Text austauschen.  </p> </li> <li> <p>\u00c4nderungen im Browser pr\u00fcfen:     Lade nun im Browser die Seite unter <code>http://localhost:8080</code> neu. Du solltest sofort deine \u00c4nderungen an der Webseite sehen.  </p> </li> <li> <p>Container-Shell verlassen:     Mit <pre><code>exit\n</code></pre>     verl\u00e4sst du die Shell im Container und bist wieder zur\u00fcck auf deinem Hostsystem.  </p> </li> </ol>"},{"location":"content/container_webinhalt_bearbeiten/#hinweis-zu-persistenz","title":"Hinweis zu Persistenz","text":"<p>Alle \u00c4nderungen, die du direkt im Container machst, sind nicht dauerhaft, sobald du den Container entfernst (<code>docker rm</code>). Wenn du deine Dateien behalten m\u00f6chtest, solltest du Docker Volumes nutzen, um die Daten au\u00dferhalb des Containers zu speichern.  </p> Dockerfile <p>In einem sp\u00e4ren Abschnitt wird erkl\u00e4rt, wie man Dockerfiles erstellt. Kehre hierher zur\u00fcck, wenn du diesen Abschnitt gelesen hast.</p> <p>Das folgende Dockerfile wird dazu verwendet <code>index.html</code> vom Host OS ins Image zu kopieren:</p> <pre><code>FROM nginx\nCOPY index.html /usr/share/nginx/html/index.html\nRUN chown nginx:nginx /usr/share/nginx/html/index.html\n</code></pre>"},{"location":"content/containers_vs_images/","title":"Container vs. Images","text":"<p>Betrachten wir nun n\u00e4her den Unterschied zwischen einem Docker Image und einem Container.</p>"},{"location":"content/containers_vs_images/#1-was-ist-ein-docker-image","title":"1. Was ist ein Docker Image?","text":"<p>Ein Docker Image ist eine unver\u00e4nderbare (schreibgesch\u00fctzte) Datei, die als Vorlage dient, um daraus einen oder mehrere Container zu erstellen. Es enth\u00e4lt alles, was eine Anwendung ben\u00f6tigt, um lauff\u00e4hig zu sein \u2013 unabh\u00e4ngig von der Umgebung, in der sie gestartet wird.   Das Ziel eines Docker Images ist es, eine vollst\u00e4ndig reproduzierbare und portable Laufzeitumgebung bereitzustellen.   Ein Image enth\u00e4lt typischerweise:</p> <ul> <li> <p>Den Anwendungscode:   Also das eigentliche Programm oder die Skripte, die ausgef\u00fchrt werden sollen.</p> </li> <li> <p>Alle Abh\u00e4ngigkeiten   Zum Beispiel Python, Node.js oder Java \u2013 je nachdem, womit die Anwendung entwickelt wurde.</p> </li> <li> <p>Systemwerkzeuge und Konfigurationen:   Dazu geh\u00f6ren Hilfsprogramme, Paketmanager oder notwendige Linux-Befehle.</p> </li> <li> <p>Umgebungsvariablen und Standardpfade:   Damit die Anwendung wei\u00df, wo bestimmte Daten liegen oder wie sie sich verhalten soll.</p> </li> <li> <p>Einen Startbefehl:   Dieser wird automatisch ausgef\u00fchrt, wenn das Image als Container gestartet wird.</p> </li> </ul> <p>Ein Docker Image wird in der Regel durch eine Dockerfile erstellt. Das ist eine einfache Textdatei, in der man Schritt f\u00fcr Schritt angibt, wie das Image aufgebaut sein soll.   Das offizielle <code>hello-world</code> Image ist ein sehr einfaches Testprogramm. Es gibt beim Starten eine kurze Best\u00e4tigung aus, dass Docker richtig funktioniert. Man kann sich den Aufbau dieses Images etwa so vorstellen:</p> <pre><code># 1. Nutze ein sehr kleines Linux-Basis-Image:\nFROM scratch\n\n# 2. F\u00fcge die kompilierten Ausgabedateien hinzu (nur eine Binary-Datei):\nADD hello /hello\n\n# 3. Definiere, welcher Befehl beim Start des Containers ausgef\u00fchrt wird:\nCMD [\"/hello\"]\n</code></pre> <p>Wenn man \u00fcber den Dockerfile, vom <code>hello-world</code> Image, mehr erfahren m\u00f6chte, dann kann man dies unter Docker Desktop tun:</p> <p></p> <p>In den meisten F\u00e4llen, m\u00f6chte man sich als Nutzer oder Entwickler nicht direkt mit der Dockerfile besch\u00e4ftigen. H\u00e4ufig verwendet man fertige Images, womit man Container erstellt und mit denen dann arbeitet. Sobald man aber ernsthaft mit Docker entwickeln, anpassen oder ver\u00f6ffentlichen will, kommt man an der Dockerfile nicht vorbei. Also reicht f\u00fcr uns erstmal einfach nur aus zu Wissen, was ein Dockerfile grob ist.</p> <p></p>"},{"location":"content/containers_vs_images/#2-was-ist-ein-docker-container","title":"2. Was ist ein Docker Container?","text":"<p>Ein Docker Container ist eine laufende oder gestoppte Instanz eines Docker Images. Man kann sich einen Container als eine Art \"lebendige Kopie\" eines Images vorstellen \u2013 also ein aktiver Prozess, der auf dem Image basiert und damit arbeitet. W\u00e4hrend das Image die Vorlage bzw. der Bauplan ist, ist der Container die ausgef\u00fchrte Anwendung.   Der Begriff \u201eContainer\u201c kommt urspr\u00fcnglich aus der Logistik: Ein Schiffscontainer hat immer die gleiche Form, aber man kann beliebige Inhalte hineinpacken \u2013 von Autos bis Bananen. Egal welcher Hafen oder welches Schiff: Der Container wird \u00fcberall gleich behandelt. Genauso funktioniert ein Docker Container:</p> <ul> <li> <p>Man kann verschiedene Anwendungen verpacken (z.\u202fB. Python-Skript, Webserver, Datenbank).</p> </li> <li> <p>Aber nach au\u00dfen sehen alle Container gleich aus \u2013 sie lassen sich standardisiert starten, stoppen, verschieben und verwalten.</p> </li> </ul> <p>Somit k\u00f6nnen wir das Bild vom Docker File \u00fcber Docker Image bis zum Docker Container vervollst\u00e4ndigen:</p> <p></p> <p>Um sich schnell ein Docker Image im Terminal zu holen, verwendet man den Befehl:</p> <pre><code>docker pull &lt;image-name&gt;\n</code></pre> <p>Wir k\u00f6nnen z.B. nochmal das <code>hello-world</code> Image downloaden:</p> <pre><code>docker pull hello-world\n</code></pre> <p></p> <p>Wir k\u00f6nnen mithilfe des folgenden Befehls alle Images, welche lokal vorhanden sind, anzeigen lassen:</p> <pre><code>docker image ls\n</code></pre> <p>Man kann sich sehr schnell einen \u00dcberblick \u00fcber die laufenden Container auf dem System verschaffen:</p> <pre><code>docker ps\n</code></pre> <p>Standardm\u00e4\u00dfig zeigt <code>docker ps</code> nur die laufenden Container an. Wir erzeugen mit <code>docker run hello-world</code> einen neuen Container, welcher gestartet wird, seine Aufgabe erf\u00fcllt und am ende beendet wird. Nun h\u00e4tten wir einen gestoppten Container welcher durch <code>docker ps</code> nicht angezeigt wird. Wenn man auch gestoppte Container sehen m\u00f6chte, muss man den Befehl so erweitern:</p> <pre><code>docker ps -a\n</code></pre> <p></p>"},{"location":"content/containers_vs_images/#3-zusammenfassung","title":"3. Zusammenfassung","text":"Aspekt Docker Image Docker Container Definition Eine schreibgesch\u00fctzte Vorlage mit allem, was eine Anwendung braucht Eine laufende oder gestoppte Instanz eines Images Zustand Statisch, unver\u00e4nderlich Dynamisch, ausf\u00fchrbar, ver\u00e4nderlich Bestandteile Anwendungscode, Bibliotheken, Konfigurationen, Startbefehl Enth\u00e4lt alle Inhalte des Images + laufende Prozesse und evtl. \u00c4nderungen Funktion Dient als Vorlage zur Erstellung von Containern F\u00fchrt die Anwendung aus Speicherort Auf dem System gespeichert als Datei/Schicht (Layer) L\u00e4uft als isolierter Prozess im RAM Erstellung \u00dcber <code>docker build</code> oder durch Herunterladen (<code>docker pull</code>) Durch Ausf\u00fchren eines Images: <code>docker run &lt;image&gt;</code> Startbefehl Wird im Image festgelegt (CMD oder ENTRYPOINT) Wird beim Start ausgef\u00fchrt Verhalten Unver\u00e4nderlich \u2013 immer gleich Kann Daten speichern, Logs erzeugen, interaktiv arbeiten Mehrfach verwendbar Ja, aus einem Image k\u00f6nnen beliebig viele Container erstellt werden Ja, aber jeder Container ist eine eigene Instanz Beispiel <code>hello-world:latest</code> <code>hopeful_morse</code> (automatisch benannter Container) Sichtbar mit Docker CLI <code>docker image ls</code> <code>docker ps -a</code> L\u00f6schbar mit <code>docker rmi &lt;image&gt;</code> (nur wenn kein Container es verwendet) <code>docker rm &lt;container&gt;</code>"},{"location":"content/custom_images/","title":"Eigene Docker-Images erstellen","text":"<p>In den vorherigen Kapiteln wurde erl\u00e4utert, wie man bestehende Images aus dem Docker Hub verwendet, wie man Container startet und wie man mit Volumes arbeitet. Nun geht es einen Schritt weiter, eigene Docker-Images erstellen. In vielen F\u00e4llen reicht es aus, ein bereits vorhandenes Docker-Image zu verwenden \u2013 zum Beispiel ein Image mit einer fertigen Webserver-Software wie Nginx oder ein Image mit der Programmiersprache Python. Diese Images findet man in der Regel auf Docker Hub, der gro\u00dfen \u00f6ffentlichen Sammlung von Images. Aber manchmal braucht man etwas Individuelles \u2013 etwas, das genau zu den eigenen Anforderungen passt. In solchen F\u00e4llen ist es sinnvoll oder sogar notwendig, ein eigenes Docker-Image zu bauen.   Wir hatten ja bereits erfahren, dass ein Docker-Image eine Art Schablone f\u00fcr Container ist. Ein Container ist dann eine laufende Instanz eines Images. Man kann sich ein Image also wie ein Installationspaket und den Container wie die tats\u00e4chlich installierte und laufende Anwendung vorstellen.   Das Dockerfile ist die zentrale Datei zum Bau eines Docker-Images. Es enth\u00e4lt Schritt-f\u00fcr-Schritt-Anweisungen, wie das Image erstellt werden soll. Wir betrachten dazu ein Beispiel:</p> <ul> <li> <p>Stellt euch vor, ihr entwickelst eine eigene Website oder ein kleines Webprojekt mit HTML, CSS und JavaScript.</p> </li> <li> <p>Man m\u00f6chtet diese Seite mit dem Webserver Nginx ausliefern.</p> </li> <li> <p>Das Standard-Image von Nginx zeigt aber nur eine Beispielseite.</p> </li> <li> <p>Damit unsere eigene Seite angezeigt wird, muss man ein Image erstellen, in dem dein HTML-Code enthalten ist.</p> </li> </ul> <p>Statt der Nginx-Standardseite soll auf <code>localhost</code> eine To-Do-Liste im Browser angezeigt werden. Daf\u00fcr ben\u00f6tigt man ein eigenes Image, das genau diesen HTML-Code enth\u00e4lt. Wir erstellen einen neuen Ordner <code>MySite</code> und \u00f6ffnen ihn in VS Code. Au\u00dferdem erstellen wir unter <code>MySite</code> noch einen weiteren Ordner mit der Bezeichnung <code>frontend</code>. Innerhalb von <code>frontend</code> liegt der Dockerfile:</p> <p></p> <p>Au\u00dferdem installieren wir noch die Docker Extension, damit wir die Autovervollst\u00e4ndigung und weitere n\u00fctzliche Funktionalit\u00e4ten erhalten:</p> <p></p> <p>Man erstellt in fast allen F\u00e4llen nicht von Null aus ein Dockerfile, sodnern baut auf anderen Docker-Images auf. Wir schreiben in die <code>dockerfile</code>:</p> <pre><code>FROM nginx\n</code></pre> <p>Die erste Zeile ist der erste und wichtigste Befehl in einem Dockerfile. Sie sagt Docker: \"Verwende das fertige Nginx-Image in der Version 1.27.0 als Ausgangsbasis f\u00fcr mein eigenes Image.\"</p> <p>Nun k\u00f6nnen wir in den <code>frontend</code>-Ordner navigieren:</p> <pre><code>cd frontend\n</code></pre> <p>Nun erstellen wir ein neues Image, basierend auf dem <code>dockerfile</code> im aktuellen Verzeichnis und geben ihm den Namen <code>mysite</code>:</p> <pre><code>docker build -t mysite .\n</code></pre> <ul> <li> <p><code>-t</code> steht f\u00fcr \"tag\", also Etikett oder Bezeichner, dieser Name hilft sp\u00e4ter dabei, das Image zu starten oder es weiterzugeben.</p> </li> <li> <p>Der Punkt <code>.</code> gibt an, welches Verzeichnis als sogenannter Build-Kontext verwendet werden soll. Das bedeutet, Docker schaut in diesem Verzeichnis nach dem Dockerfile und hat nur Zugriff auf Dateien in diesem Ordner (und Unterordner). Docker hat beim Bauen nur Zugriff auf Dateien innerhalb des angegebenen Kontextes \u2013 also nicht auf \u00fcbergeordnete Ordner!</p> </li> </ul> <p></p> <p>Nun sollte unser Image mit dem Namen <code>mysite</code> in Docker Desktop sichtbar sein:</p> <p></p> <p>Wir k\u00f6nnen ihn ausf\u00fchren, aber momentan ist es nichts weiter als eine Kopie vom <code>nginx</code>-Image. Wir werden nun weiter unser <code>dockerfile</code> anpassen. Dazu erstellen wir unter dem <code>frontend</code>-Ordner einen <code>static</code>-Ordner mit einer html-Datei, welche den Namen <code>index.html</code> hat:</p> <p></p> <p>index.html:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n  &lt;meta charset=\"UTF-8\" /&gt;\n  &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"/&gt;\n  &lt;title&gt;Frontend-only Todo List&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1&gt;Todo List&lt;/h1&gt;\n  &lt;input type=\"text\" id=\"newItem\" placeholder=\"Enter a new item\" /&gt;\n  &lt;button onclick=\"addItem()\"&gt;Add&lt;/button&gt;\n  &lt;ul id=\"todoList\"&gt;&lt;/ul&gt;\n\n  &lt;script&gt;\n    // In-Memory-Speicher f\u00fcr unsere Aufgaben\n    let todos = [];\n\n    function renderTodos() {\n      const list = document.getElementById('todoList');\n      list.innerHTML = '';\n      todos.forEach((todo, index) =&gt; {\n        const li = document.createElement('li');\n        li.textContent = todo;\n\n        const deleteBtn = document.createElement('button');\n        deleteBtn.textContent = 'Delete';\n        deleteBtn.onclick = () =&gt; {\n          todos.splice(index, 1);\n          renderTodos();\n        };\n\n        li.appendChild(deleteBtn);\n        list.appendChild(li);\n      });\n    }\n\n    function addItem() {\n      const input = document.getElementById('newItem');\n      const value = input.value.trim();\n      if (value !== '') {\n        todos.push(value);\n        input.value = '';\n        renderTodos();\n      }\n    }\n\n    // Initialanzeige\n    renderTodos();\n  &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Bisher enth\u00e4lt unser Docker-Image nur den standardm\u00e4\u00dfigen HTML-Inhalt von Nginx. Nun wollen wir diesen durch unsere eigene Datei <code>index.html</code> ersetzen. Daf\u00fcr m\u00fcssen wir unsere HTML-Datei in den richtigen Ort innerhalb des Images kopieren \u2013 dorthin, wo Nginx nach statischen Inhalten sucht. Der Ort, an dem Nginx standardm\u00e4\u00dfig HTML-Dateien erwartet, ist:</p> <pre><code>/usr/share/nginx/html\n</code></pre> <p>Daher passen wir unseren <code>dockerfile</code> an:</p> <pre><code>COPY static /usr/share/nginx/html\n</code></pre> <p>Da sich unser Dockerfile ver\u00e4ndert hat, m\u00fcssen wir das Image neu bauen:</p> <pre><code>docker build -t mysite .\n</code></pre> <p>In Docker Desktop sollte man sehen dass k\u00fcrzlich unser Image erstellt wurde:</p> <p></p> <p>Jetzt wollen wir unser eigenes Image testen. Daf\u00fcr starten wir einen Container und ver\u00f6ffentlichen den Port 80 auf unserem lokalen Rechner:</p> <pre><code>docker run -p 80:80 mysite\n</code></pre> <p>Der Container startet Nginx \u2013 und der Nginx-Server zeigt jetzt unsere eigene To-Do-Liste im Browser an. Dazu \u00f6ffnen wir auf unserem Computer <code>http://localhost</code></p> <p></p> <p>Es ist momentan eine reine Frontend-Anwendung, man sollte auch Todo-Items hinzuf\u00fcgen k\u00f6nnen:</p> <p></p> <p>Wir k\u00f6nnten nun pr\u00fcfen ob im Container die <code>index.html</code>-Datei wirklich hinterlegt wurde. In Docker Desktop gehen wir unter \"Containers\" auf den momentan ausgef\u00fchrten Container, mit dem Image <code>mysite</code>:</p> <p></p> <p>Wenn wir in der Container-UI sind, klicken wir noch auf \"Exec\":</p> <p></p> <p>Jetzt geben wir ein:</p> <pre><code>cd /usr/share/nginx/html\nls\n</code></pre> <p>Hier sollte man die <code>index.html</code>-Datei sehen:</p> <p></p> <p>Wir k\u00f6nnen auch den Inhalt der Datei anschauen:</p> <pre><code>cat index.html\n</code></pre> <p></p> <p>In dem Verzeichnis ist nicht nur unsere <code>index.html</code> Datei vorhanden, sondern noch eine <code>50x.html</code>-Datei, welche welche von Nginx als Standard-Fehlermeldungsseite f\u00fcr Serverfehler (z.B. \"500 Internal Server Error\") verwendet wird. Diese Datei stammt aus dem urspr\u00fcnglichen Nginx-Image und wird automatisch mitgeliefert. Wir m\u00f6chten dass diese Datei nicht vorhanden ist, dazu erweitern wir unser <code>dockerfile</code>:</p> <p>dockerfile: <pre><code>FROM nginx:1.27.0\n\n# Webverzeichnis html l\u00f6schen:\nRUN rm -rf /usr/share/nginx/html\n\n# Eigene HTML-Dateien hinzuf\u00fcgen\nCOPY static /usr/share/nginx/html\n</code></pre></p> <p></p> <p>Da sich unser Dockerfile ver\u00e4ndert hat, m\u00fcssen wir das Image neu bauen:</p> <pre><code>docker build -t mysite .\n</code></pre> <p>Jetzt wollen wir wieder unser eigenes Image testen. Daf\u00fcr starten wir einen Container:</p> <pre><code>docker run -p 80:80 mysite\n</code></pre> <p>Unsere Todo List unter <code>http://localhost</code> sollte weiterhin ohne Probleme funktionieren. Jetzt m\u00fcsste aber NUR die Datei <code>index.html</code> vorhanden sein, das Testen wir durch:</p> <pre><code>cd /usr/share/nginx/html\nls\n</code></pre> <p></p> <p>Nun haben wir gelernt, wie man ein eigenes Docker-Image erstellt und darin eine statische Website mit Nginx bereitstellt. Am Ende haben wir ein vollst\u00e4ndiges Docker-Image gebaut, das eine funktionierende To-Do-Liste im Browser darstellt \u2013 und das ganz ohne Backend, rein im Frontend mit JavaScript.</p>"},{"location":"content/custom_images/#ubungsaufgabe-dockerfile-befehle-zuordnen","title":"\u00dcbungsaufgabe: Dockerfile-Befehle zuordnen","text":"Windows-Installation \u2014 Dockerfile-Befehle zuordnen <p>Ordne die Dockerfile-Anweisungen (1\u20136) den Bedeutungen (A\u2013F) zu.</p> <p>Anweisungen:</p> <ol> <li> <p><code>FROM ubuntu:22.04</code></p> </li> <li> <p><code>RUN apt-get update &amp;&amp; apt-get install -y curl</code></p> </li> <li> <p><code>COPY . /app</code></p> </li> <li> <p><code>WORKDIR /app</code></p> </li> <li> <p><code>EXPOSE 8080</code></p> </li> <li> <p><code>CMD [\"nginx\", \"-g\", \"daemon off;\"]</code></p> </li> </ol> <p>Bedeutungen:</p> <p>A. Legt das Basis-Image fest</p> <p>B. F\u00fchrt Befehle w\u00e4hrend des Image-Builds aus (erstellt Schicht)</p> <p>C. Kopiert Dateien aus dem Build-Kontext ins Image</p> <p>D. Setzt das Arbeitsverzeichnis f\u00fcr nachfolgende Anweisungen</p> <p>E. Deklariert einen Port, den der Container nutzt (Dokumentation)</p> <p>F. Standardbefehl, der beim Containerstart ausgef\u00fchrt wird</p> L\u00f6sung <p>Zuordnung:</p> <ul> <li>1 \u2192 A (Basis-Image)</li> <li>2 \u2192 B (Build-Schritt)</li> <li>3 \u2192 C (Dateien kopieren)</li> <li>4 \u2192 D (Arbeitsverzeichnis)</li> <li>5 \u2192 E (Port-Deklaration, kein Publish)</li> <li>6 \u2192 F (Startkommando)</li> </ul>"},{"location":"content/custom_images_01/","title":"Eigene Docker-Images erstellen - Erweitert","text":"<p>Kehren wir zur\u00fccl zu unserer Anwendung mit der Todo-Liste zur\u00fcck. Wir hatten bereits das Frontend erstellt und ein <code>dockerfile</code>. Wir werden diese Anwendung mit einem Fast-API Backend erweitern. Wir erweitern nun unser Projektverzeichnis mit der folgenden Struktur:</p> <p></p> <p>Au\u00dferdem wird noch eine virtuelle Entwicklungsumgebung <code>.venv</code> ben\u00f6tigt. Im Terminal geben wir ein:</p> <p>Ordner <code>.venv</code> erstellen: <pre><code>\\MySite&gt;python -m venv .venv\n</code></pre></p> <p>Viruelle Entwicklungsumgebung aktivieren: <pre><code>\\MySite&gt;.venv\\Scripts\\activate\n</code></pre></p> <p>Mit <code>CTRL + SHIFT + P</code> \u00f6ffnen wir in VS-Code \"Command Palette\", w\u00e4hlen \"Python: Select Interpreter\" aus und wechseln zum <code>.venv</code> wo \"Recommended\" steht:</p> <p></p> <p>Nun installieren wir FastAPI: <pre><code>\\MySite&gt;pip install fastapi\n</code></pre></p> <p>Auch der Server f\u00fcr FastAPI, muss installiert werden: <pre><code>\\MySite&gt;pip install uvicorn\n</code></pre></p> <p>Au\u00dferdem erstellen wir noch eine <code>requirements.txt</code>-Datei direkt im <code>backend</code>-Ordner: <pre><code>\\MySite&gt;pip freeze &gt; requirements.txt\n</code></pre></p> <p>In die <code>main.py</code> Datei f\u00fcgen wir den folgenden Code ein:</p> <pre><code># Importieren der Hauptklasse um die Webanwendung zu erstellen und eine Klasse zur kontrollierten Bhandlung von Fehlermeldungen:\nfrom fastapi import FastAPI, HTTPException\n# Basis f\u00fcr die Datenmodelle (Validierung):\nfrom pydantic import BaseModel\n\n# Der Einstiegspunkt:\napp = FastAPI()\n\n# Beschreibt ein vollst\u00e4ndiges To-do-Objekt mit ID und Inhalt:\nclass TodoItem(BaseModel):\n    id: int\n    content: str\n\n# beschreibt nur den Inhalt eines neuen To-do:\nclass TodoItemCreate(BaseModel):\n    content: str\n\n# Eine einfache Python-Liste, die alle Aufgaben enth\u00e4lt:\ntodos: list[TodoItem] = []\n# Eine Z\u00e4hlvariable, um jedem Todo eine eindeutige ID zu geben:\nid_counter = 1\n\n@app.post(\"/todos\", response_model=TodoItem)\nasync def create_todo(item: TodoItemCreate):\n    global id_counter\n    new_todo = TodoItem(id=id_counter, content=item.content)\n    todos.append(new_todo)\n    id_counter += 1\n    return new_todo\n\n@app.get(\"/todos\", response_model=list[TodoItem])\nasync def read_todos():\n   return todos\n\n@app.delete(\"/todos/{todo_id}\")\nasync def delete_todo(todo_id: int):\n    for index, todo in enumerate(todos):\n        if todo.id == todo_id:\n            todos.pop(index)\n            return {\"message\": \"Todo deleted successfully\"}\n    raise HTTPException(status_code=404, detail=\"Todo not found\")\n</code></pre> <p>Direkt im <code>backend</code>-Ordner erstellen wir eine <code>dockerfile</code>-Datei:</p> <p></p> <p>Der Inhalt ist in dieser Datei:</p> <p>dockerfile im backend: <pre><code>FROM python:3.12-slim\n\n# Setzt das Arbeitsverzeichnis im Container:\nWORKDIR /app\n\n# Kopiert die Datei \"requirements.txt\" aus dem aktuellen Projektordner in den Container:\nCOPY requirements.txt requirements.txt\n\n# Pakete aus \"requirements.txt\" installieren:\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Code der Anwendung wird kopiert in \"/app/mysite\":\nCOPY src/mysite mysite\n\n# F\u00fcr Dokumentation,der Container \"h\u00f6rt\" auf Port 8000 (Standard-Port f\u00fcr FastAPI mit Uvicorn):\nEXPOSE 8000\n\n# Startbefehl f\u00fcr den Container:\nCMD [ \"uvicorn\", \"mysite.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\" ]\n</code></pre></p> <p>Nun ist es an der Zeit, das Docker-Image zu bauen. Dazu wechseln wir im Terminal in den <code>backend</code>-Ordner und f\u00fchren folgenden Befehl aus:</p> <pre><code>docker build -t mysite-backend .\n</code></pre> <p>In Docker Desktop sollte nun das neue Image erscheinen:</p> <p></p> <p>Nun starten wir den Container, mithilfe dieses Images:</p> <pre><code>docker run -p 8000:8000 mysite-backend\n</code></pre> <p>Jetzt kann man wie gewohnt \u00fcber <code>http://localhost:8000/docs</code> die interaktive Swagger-UI Dokumentationsseite von FastAPI besuchen:</p> <p></p> <p>Jetzt muss im Frontend die <code>index.html</code>-Datei angepasst werden, damit wird mit dem Backend interagieren k\u00f6nnen. Dazu soll die <code>index.html</code>-Datei mit dem folgenden code ersetzt werden:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Minimal Todo List&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Todo List&lt;/h1&gt;\n    &lt;input type=\"text\" id=\"newItem\" placeholder=\"Enter a new item\"&gt;\n    &lt;button onclick=\"addItem()\"&gt;Add&lt;/button&gt;\n    &lt;ul id=\"todoList\"&gt;&lt;/ul&gt;\n\n    &lt;script&gt;\n        const API_URL = 'http://localhost:8000';\n\n        async function fetchTodos() {\n            const response = await fetch(`${API_URL}/todos`);\n            const todos = await response.json();\n            const list = document.getElementById('todoList');\n            list.innerHTML = '';\n            todos.forEach(todo =&gt; {\n                const li = document.createElement('li');\n                li.textContent = todo.content;\n                const deleteBtn = document.createElement('button');\n                deleteBtn.textContent = 'Delete';\n                deleteBtn.onclick = () =&gt; deleteItem(todo.id);\n                li.appendChild(deleteBtn);\n                list.appendChild(li);\n            });\n        }\n\n        async function addItem() {\n            const input = document.getElementById('newItem');\n            if (input.value.trim() !== '') {\n                const response = await fetch(`${API_URL}/todos`, {\n                    method: 'POST',\n                    headers: {\n                        'Content-Type': 'application/json',\n                    },\n                    body: JSON.stringify({ content: input.value }),\n                });\n                if (response.ok) {\n                    input.value = '';\n                    fetchTodos();\n                }\n            }\n        }\n\n        async function deleteItem(id) {\n            const response = await fetch(`${API_URL}/todos/${id}`, {\n                method: 'DELETE',\n            });\n            if (response.ok) {\n                fetchTodos();\n            }\n        }\n\n        fetchTodos();\n    &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Nun muss nat\u00fcrlich ein neues Image f\u00fcr das Frontend erstellt werden. Dazu wechseln wir in einem neuen Terminal in das <code>frontend</code>-Verzeichnis und f\u00fchren folgenden Befehl aus:</p> <pre><code>docker build -t mysite-frontend .\n</code></pre> <p>In Docker Desktop m\u00fcsste nun das <code>mysite-frontend</code>-Image sichtbar sein:</p> <p></p> <p>Jetzt f\u00fchren wir auch den Container f\u00fcr das Frontend aus:</p> <pre><code>docker run -p 80:80 -d mysite-frontend\n</code></pre> <p>Die FastAPi Swagger-UI Seite ist immer noch erreichbar unter http://localhost:8000/docs und jetzt auch das Frontend unter http://localhost/. Im Frontend \u00f6ffne ich die DevTools, gehe zu \"Network\" und lade die Seite neu:</p> <p></p> <p>Hier sieht man den sogenannten CORS-Fehler. Ein CORS-Fehler (Cross-Origin Resource Sharing) bedeutet, dass unser Frontend <code>http://localhost/</code> versucht, mit dem Backend <code>http://localhost:8000/docs</code>  zu kommunizieren, aber der Browser die Verbindung blockiert, weil das Backend nicht explizit erlaubt, von einer anderen Domain aus angesprochen zu werden.  </p> <p>CORS ist ein Sicherheitsmechanismus im Browser, der verhindert, dass Webseiten aus einer anderen Quelle (Origin) unkontrolliert auf Ressourcen zugreifen. Dabei handelt es sich um ein Standardverhalten von Browsern. Damit das Backend solche Anfragen erlaubt, muss man CORS freischalten \u2013 das geht mit der sogenannten <code>CORSMiddleware</code>. Nach der Anpassung sieht die <code>main.py</code>-Datei so aus:</p> <pre><code># Importieren der Hauptklasse um die Webanwendung zu erstellen und eine Klasse zur kontrollierten Bhandlung von Fehlermeldungen:\nfrom fastapi import FastAPI, HTTPException\n# Basis f\u00fcr die Datenmodelle (Validierung):\nfrom pydantic import BaseModel\n# CORS-Middleware importieren, um CORS-Fehler zu beheben:\nfrom fastapi.middleware.cors import CORSMiddleware  \n\n# Der Einstiegspunkt:\napp = FastAPI()\n\n# CORS zulassen:\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost\"],  # Hier die URL des Frontends\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Beschreibt ein vollst\u00e4ndiges To-do-Objekt mit ID und Inhalt:\nclass TodoItem(BaseModel):\n    id: int\n    content: str\n\n# beschreibt nur den Inhalt eines neuen To-do:\nclass TodoItemCreate(BaseModel):\n    content: str\n\n# Eine einfache Python-Liste, die alle Aufgaben enth\u00e4lt:\ntodos: list[TodoItem] = []\n# Eine Z\u00e4hlvariable, um jedem Todo eine eindeutige ID zu geben:\nid_counter = 1\n\n@app.post(\"/todos\", response_model=TodoItem)\nasync def create_todo(item: TodoItemCreate):\n    global id_counter\n    new_todo = TodoItem(id=id_counter, content=item.content)\n    todos.append(new_todo)\n    id_counter += 1\n    return new_todo\n\n@app.get(\"/todos\", response_model=list[TodoItem])\nasync def read_todos():\n   return todos\n\n@app.delete(\"/todos/{todo_id}\")\nasync def delete_todo(todo_id: int):\n    for index, todo in enumerate(todos):\n        if todo.id == todo_id:\n            todos.pop(index)\n            return {\"message\": \"Todo deleted successfully\"}\n    raise HTTPException(status_code=404, detail=\"Todo not found\")\n</code></pre> <p>Nun m\u00fcssen wir nochmal in das <code>backend</code>-Verzeichnis wechseln und einen neuen Docker-Image erstellen:</p> <pre><code>docker build -t mysite-backend .\n</code></pre> <p>Nun starten wir den Container, mithilfe dieses Images:</p> <pre><code>docker run -p 8000:8000 mysite-backend\n</code></pre> <p>Jetzt sind die beiden Container f\u00fcr das Frontend und Backend aktiv:</p> <p></p> <p>Wenn wir nochmal das Frontend aufrufen, sollte der CORS-Fehler verschwinden:</p> <p></p> <p>Man kann jetzt die Todos hinzuf\u00fcgen und unter \"Networks\" in den Dev-Tools beobachten wie das Frontend mit dem Backend kommuniziert:</p> <p></p>"},{"location":"content/custom_images_01/#fazit","title":"Fazit","text":"<p>In diesem Kapitel wurde Schritt f\u00fcr Schritt gezeigt, wie man eine vollst\u00e4ndige Webanwendung mit Frontend und einem FastAPI-Backend in separaten Docker-Containern betreiben kann. Dabei lag der Schwerpunkt auf einer praxisnahen Umsetzung: vom Einrichten der Verzeichnisstruktur \u00fcber das Erstellen eigener Dockerfiles bis hin zur Bew\u00e4ltigung realer Herausforderungen \u2013 etwa CORS-Fehlern, die bei der Kommunikation zwischen verschiedenen Containern auftreten k\u00f6nnen.   Ein zentrales Prinzip von Docker ist die Trennung von Anwendungscode und Laufzeitumgebung. Durch das Erstellen eines eigenen Dockerfiles f\u00fcr das Backend und sp\u00e4ter auch f\u00fcr das Frontend wurde deutlich:</p> <ul> <li> <p>Jede Anwendung l\u00e4uft isoliert in ihrem eigenen Container, unabh\u00e4ngig von anderen Komponenten.</p> </li> <li> <p>Alle Abh\u00e4ngigkeiten, Konfigurationen und Installationen sind im Container selbst enthalten \u2013 es wird nichts vom Host-System ben\u00f6tigt.</p> </li> <li> <p>Dadurch l\u00e4sst sich die Anwendung plattformunabh\u00e4ngig betreiben \u2013 egal ob auf Windows, macOS oder Linux.</p> </li> </ul> <p>Ein weiteres zentrales Lernziel war das Verst\u00e4ndnis f\u00fcr den Aufbau eines Dockerfiles: Es beschreibt pr\u00e4zise, wie ein Docker-Image zusammengesetzt ist \u2013 von der Basis \u00fcber die Paketinstallation bis hin zum Startbefehl. Damit wird deutlich, wie man Anwendungen sauber paketiert, automatisiert ausliefert und in reproduzierbaren Umgebungen betreibt.</p>"},{"location":"content/devcontainer/","title":"Dev-Container","text":"Video <p>Dev-Container sind eine spezielle Art von Container. Ein solcher enth\u00e4lt nicht nur die App, sondern die gesamte Entwicklungsumgebung:</p> <ul> <li> <p>Betriebssystem-Tools (z. B. Git, curl, make)</p> </li> <li> <p>Programmiersprachen &amp; Compiler</p> </li> <li> <p>Build-Tools und Debugger</p> </li> <li> <p>Editor-Plugins, Formatierer, Linter</p> </li> <li> <p>Zugriff auf Quellcode, Git, Terminal etc.</p> </li> </ul> <p>Ziel: Entwickler arbeiten direkt innerhalb eines Containers. Im besten Fall bietet er die gleiche Umgebung, wie die sp\u00e4tere Produktionsumgebung.</p> <p>Beispiel: Dev-Container f\u00fcr eine Flask App mit Python Umgebung und Installation der requirements</p> Devcontainer.json<pre><code>// For format details, see https://aka.ms/devcontainer.json. For config options, see the\n// README at: https://github.com/devcontainers/templates/tree/main/src/python\n{\n    \"name\": \"Python 3\",\n    \"image\": \"mcr.microsoft.com/devcontainers/python:1-3.12-bullseye\",\n\n    // Features of the devcontainer. More info: https://containers.dev/features.\n    // \"features\": {},\n\n    // Use 'forwardPorts' to make a list of ports inside the container available locally.\n    \"forwardPorts\": [3000],\n\n    // Use 'postCreateCommand' to run commands after the container is created.\n    \"postCreateCommand\": \"pip3 install --user -r requirements.txt\"\n\n    // Configure tool-specific properties.\n    // \"customizations\": {},\n\n    // Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.\n    // \"remoteUser\": \"root\"\n}\n</code></pre> Requirements.txt<pre><code>flask\n</code></pre> app.py<pre><code>from flask import Flask\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef home():\n    return \"Hallo aus dem Dev-Container mit Python!\"\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", port=3000, debug=True\n</code></pre> <p>Wenn man das ganze so anlegt:</p> <pre><code>projektname/\n\u251c\u2500 .devcontainer/\n\u2502  \u2514\u2500 devcontainer.json    \u2190 nur Konfig hier!\n\u251c\u2500 requirements.txt        \u2190 Projektabh\u00e4ngigkeiten\n\u251c\u2500 app.py                  \u2190 Quellcode\n\u251c\u2500 tests/                  \u2190 Tests\n\u2514\u2500 README.md\n</code></pre> <p>Kann man zuerst einmal die Dev Containers Erweiterung von Microsoft installieren:</p> <p></p> <p>Dann Docker Desktop starten, als n\u00e4chstes dr\u00fcckt man Strg+Shift+P oder View -&gt; Command Palette und gibt ein \u201eDev Containers: Reopen in Container\u201c. Beim erstmaligen ausf\u00fchren wird man gefragt ob man Docker in WSL installieren will, das best\u00e4tigt man mit ja. Danach muss man falls noch nicht geschehen Docker Desktop herunterladen und starten. Anschlie\u00dfend \u00f6ffnet sich der Container und die Requirements werden installiert. Hiernach kann ganz normal mit Python die app.py starten, also mit python3 app.py, dann sollte es wie folgt aussehen, wenn man localhost:3000 im Browser \u00f6ffnet:</p> <p></p> <p>Modell\u00fcbersicht</p> <p></p> <p>Wir haben jetzt:</p> <ul> <li> <p>Einen funktionierenden Python Dev-Container</p> </li> <li> <p>Automatische Paketinstallation \u00fcber requirements.txt</p> </li> <li> <p>Einen Webserver im Container gestartet</p> </li> <li> <p>Portweiterleitung eingerichtet</p> </li> <li> <p>Entwicklungsumgebung isoliert und reproduzierbar gemacht</p> </li> </ul> <p>Somit l\u00e4uft das Projekt hier in der gleichen Umgebung, die sp\u00e4ter z.B. im CI-System oder in Produktion verwendet wird.</p> <p>Vorteile:</p> <ul> <li> <p>Keine \u201el\u00e4uft nur auf meinem Rechner\u201c-Probleme</p> </li> <li> <p>Gleiche Umgebung f\u00fcr alle im Team</p> </li> <li> <p>Leichtes Onboarding neuer Mitarbeitender / Sch\u00fcler:innen</p> </li> <li> <p>Umgebung ist reproduzierbar \u2192 CI/CD-kompatibel</p> </li> <li> <p>Spart Zeit bei Setup und Fehlersuche</p> </li> </ul> <p>Beispiel aus der Praxis:</p> <p>Ein Entwickler nutzt Windows, einer macOS, einer Linux \u2013 trotzdem entwickeln alle im selben Container mit exakt denselben Versionen von Python, Tools und Libraries.</p> Bestandteil Erkl\u00e4rung Beispiel .devcontainer/ Ordner mit allen Container-Konfigs \u2013 devcontainer.json Hauptkonfigurationsdatei <code>\"image\": \"mcr.microsoft.com/devcontainers/python:3.12\"</code> Docker-Image Basisumgebung mit OS &amp; Tools Python, Node, Ubuntu etc. forwardPorts Ports, die aus dem Container verf\u00fcgbar gemacht werden 3000, 5000 postCreateCommand Automatische Befehle nach dem Erstellen <code>pip install -r requirements.txt</code> customizations Extensions &amp; Editor-Einstellungen Python-Plugin, Linter etc. (optional) Dockerfile Wenn man eigene Images bauen will <code>FROM python:3.12-slim</code> <ul> <li> <p>Alle Befehle im Terminal laufen im Container</p> </li> <li> <p>Installierte Pakete beeinflussen nicht das Host-System</p> </li> <li> <p>Debugging, Linting, Tests funktionieren wie gewohnt</p> </li> <li> <p>Auch Git funktioniert normal (Commit, Push etc.)</p> </li> </ul> <p>Ein weiteres Beispiel f\u00fcr einen Dev-Container:</p> Devcontainer.json<pre><code>{\n    \"name\": \"Node.js Dev Container\",\n    \"image\": \"mcr.microsoft.com/devcontainers/javascript-node:18\",\n    \"forwardPorts\": [3000],\n    \"postCreateCommand\": \"npm install\",\n    \"customizations\": {\n        \"vscode\": {\n            \"extensions\": [\"dbaeumer.vscode-eslint\"]\n        }\n    }\n}\n</code></pre> <p>Was passiert hier?</p> <ul> <li>VS Code startet automatisch einen Container mit Node.js, Git, npm, ESLint usw.</li> <li>Projekt wird in diesen Container gemountet</li> <li>Man entwickelt, installiert Abh\u00e4ngigkeiten und startet die App im Container nicht auf dem lokalen Rechner</li> </ul> <p>Wichtige Befehle und was sie bringen:</p> <ul> <li>cat /etc/os-release \u2192 Linux des Containers anzeigen</li> </ul>"},{"location":"content/devcontainer/#weiterfuhrend","title":"Weiterf\u00fchrend","text":"Video Video"},{"location":"content/docker_windows_installation/","title":"Installation auf Windows","text":"<p>Die Installation von Docker auf Windows ist etwas umst\u00e4ndlicher als auf Linux. Docker ben\u00f6tigt unter Windows eine virtuelle Linux-Umgebung, weil der Windows-Kernel Container nicht nativ unterst\u00fctzt. Unter der folgenden Seite https://docs.docker.com/desktop/setup/install/windows-install/ w\u00e4hlt man als erstes <code>Docker Desktop for Windows - x86_64</code>:</p> <p></p> <p>Dadurch wird eine EXE-Datei heruntergeladen. Unter <code>System requirements</code> steht noch das bestimmte Anforderungen erf\u00fcllt werden m\u00fcssen:</p> <p></p> <p>Dabei wird der sogenannte <code>WSL2</code> ben\u00f6tigt. Es ist eine Technologie von Microsoft, die es erlaubt, Linux direkt unter Windows auszuf\u00fchren \u2013 und zwar nicht als Emulation, sondern als echter Linux-Kernel, der in einer leichtgewichtigen virtuellen Maschine l\u00e4uft. Docker verwendet Linux-Container-Technologie, die auf dem Linux-Kernel basiert (z.\u202fB. Namespaces, cgroups). Da Windows keinen Linux-Kernel hat, braucht man eine Art \u201eUnterbau\u201c, um diese Container korrekt laufen zu lassen.  </p> <p>Um herauszufinden ob <code>WSL2</code> auf dem PC vorhanden ist, \u00f6ffnet man CMD. Anschlie\u00dfend gibt man <code>WSL</code> ein, falls eine so \u00e4hnliche Ausgabe erzeugt wird, ist <code>WSL</code> vorhanden:</p> <p></p> <p>Falls jedoch <code>WSL</code> nicht vorhanden ist, kann man mit <code>wsl --install</code> die Installation durchf\u00fchren.   Achtet darauf dass auch eine bestimmte Windows Version erforderlich ist:</p> <p></p> <p>Die genau Windows-Version, welche unterst\u00fctzt wird, findet man auf der Installationsseite. In CMD kann man mit <code>winver</code> herausfinden, welche Windows-Version auf dem Computer installiert ist:</p> <p></p> <p>Nun muss man das <code>WSL2</code> feature einschalten. Dazu suche ich unter Start nach <code>Turn Windows features on or off</code> und klicke drauf. Es erscheint folgendes Fenster:</p> <p></p> <p>Innerhalb der Liste suchen wir nach <code>Windows Subsystem for Linux</code> und durch einen Klick in die Checkbox wird dieses feature eingeschaltet. Anschlie\u00dfend best\u00e4tigt man mit <code>OK</code>:</p> <p></p> <p>Anschlie\u00dfend erscheint folgendes Fenster, wobei wir auf <code>Don't restart</code> klicken, da wir sp\u00e4ter einen Neustart durchf\u00fchren:</p> <p></p> <p>Als n\u00e4chstes m\u00fcssen wir pr\u00fcfen ob die Virtualisierung unter Windows eingeschaltet ist. Dazu klicken wir <code>CRTL + SHIFT + ESCAPE</code>, wodurch sich der Task Manager \u00f6ffnet. Unter <code>Performance</code> kann man sehen ob die Virtualisierung eingeschaltet ist:</p> <p></p> <p>Nun ist es an der Zeit die EXE-Datei, welche wir am Anfang heruntergeladen hatten, auszuf\u00fchren:</p> <p></p> <p>Anschlie\u00dfend dr\u00fccken wir auf <code>OK</code> und die Installation startet:</p> <p></p> <p>Wenn die Installation erfolgreich war, sollte so ein Fenster zu sehen sein:</p> <p></p> <p>Nun ist es an der Zeit dem Computer neu zu starten. Dann sollte so ein Fenster erscheinen:</p> <p></p> <p>Wir verwenden die empfohlenen Einstellungen:</p> <p></p> <p>Alle anderen Fragen die nun kommen kann man \u00fcberspringen oder einfach ausf\u00fcllen:</p> <p></p> <p>So sieht am Ende das finale Fenster aus:</p> <p></p> <p>Docker Desktop bietet eine benutzerfreundliche M\u00f6glichkeit, mit Containern zu arbeiten, ohne zwingend \u00fcber die Kommandozeile arbeiten zu m\u00fcssen. Insbesondere f\u00fcr Entwickler, die in einer lokalen Umgebung mit Containern experimentieren, testen oder entwickeln m\u00f6chten, ist Docker Desktop ein n\u00fctzliches Werkzeug.  </p> <p>Docker Desktop enth\u00e4lt unter anderem:</p> <ul> <li> <p>Docker Engine:   Das ist die Laufzeitumgebung f\u00fcr die Container bzw. der zentrale Dienst, der Container baut, startet und verwaltet. Es ist also das technische R\u00fcckgrat von allem, was Docker erm\u00f6glicht.</p> </li> <li> <p>Docker CLI:   CLI steht f\u00fcr Command Line Interface, also Kommandozeilen-Schnittstelle. Die Docker CLI ist das Werkzeug, mit dem man Docker \u00fcber die Eingabe von Textbefehlen steuern kann \u2013 ganz ohne grafische Oberfl\u00e4che. Ein CLI-Programm wird im Terminal (z.B. PowerShell, CMD, bash...) verwendet. Es basiert auf Textbefehlen, die vom Benutzer eingegeben werden, und gibt ebenfalls Text als Antwort zur\u00fcck.</p> </li> <li> <p>Docker Compose:   Docker Compose ist ein Werkzeug, mit dem man mehrere Container gleichzeitig starten und verwalten kann. Man beschreibt die gesamte Anwendung in einer YAML-Datei \u2013 das ist eine einfache Textdatei mit einer bestimmten Struktur.</p> </li> <li> <p>GUI (Dashboard):    Eine grafische Oberfl\u00e4che zur Verwaltung von Containern, Images, Volumes und Netzwerken.</p> </li> <li> <p>Kubernetes:   Ein Werkzeug zur Verwaltung vieler Container auf einmal \u2013 sozusagen ein \"Container-Orchester\".   W\u00e4hrend Docker daf\u00fcr da ist, einen Container oder ein paar Container zu starten, \u00fcbernimmt Kubernetes die Steuerung von vielen Containern auf vielen Rechnern. In Docker Desktop ist Kubernetes optional enthalten.</p> </li> </ul> <p>Seit 2021 ist Docker Desktop f\u00fcr kommerzielle Nutzung kostenpflichtig, wenn das Unternehmen mehr als eine bestimmte Anzahl von Mitarbeitern bzw. Umsatz hat. F\u00fcr Einzelpersonen, Bildungseinrichtungen (z.B. Hochschulen) und kleinere Unternehmen bleibt die Nutzung jedoch kostenfrei. Dennoch ist eine Anmeldung mit einem Docker Hub Account erforderlich.   Viele Dinge in Docker Desktop funktionieren auch ohne Account, vor allem f\u00fcr den lokalen Gebrauch. Aber es gibt wichtige Vorteile, wenn man sich einen kostenlosen Docker-Account erstellt. Ein Docker-Account (kostenlos) erm\u00f6glicht Zugriff auf zus\u00e4tzliche Online-Funktionen und Cloud-Dienste von Docker, die besonders bei der Zusammenarbeit und bei komplexeren Projekten n\u00fctzlich sind.</p> <p>Testen der Installation:</p> <p>Bevor man mit komplexen Anwendungen in Docker arbeitet, ist es sinnvoll, mit einem einfachen Beispiel zu starten \u2013 der sogenannten \"Hello World\"-Anwendung. Diese Anwendung ist ein Mini-Container, der nur dazu dient, zu pr\u00fcfen, ob Docker korrekt installiert ist und Container funktionieren. Sie ist wie ein \"Testlauf\", bei dem Docker einmal alles durchspielt:</p> <ul> <li> <p>ein Container wird gestartet,</p> </li> <li> <p>eine einfache Aufgabe wird ausgef\u00fchrt,</p> </li> <li> <p>Docker gibt eine R\u00fcckmeldung.</p> </li> </ul> <p>Sobald Docker installiert ist, gibt man im Terminal (z.B. CMD, Terminal oder PowerShell) folgenden Befehl ein:</p> <pre><code>docker run hello-world\n</code></pre> <p>Was passiert nun dabei? 1. Der Befehl wird \u00fcber CLI an Docker Engine geschickt:</p> <ul> <li> <p><code>docker run</code> bedeutet: \"Starte einen Container aus einem Image.\"</p> </li> <li> <p>Ein Image ist wie ein Bauplan, der alles enth\u00e4lt, was eine Anwendung zum Laufen braucht \u2013 z.B. Programmcode, Bibliotheken und Einstellungen.</p> </li> <li> <p><code>hello-world</code> ist der Name des Images.</p> </li> <li> <p>Docker sucht lokal nach dem Image:</p> </li> <li> <p>Wenn das Image noch nicht vorhanden ist, wird es automatisch von Docker Hub heruntergeladen.</p> </li> <li> <p>Docker Hub ist wie ein App-Store f\u00fcr Container. Dort findet man fertige Images und kann auch eigene Images hochladen.</p> </li> <li> <p>Docker startet einen Container aus dem Image:</p> </li> <li> <p>Der Container f\u00fchrt ein kleines Programm aus, das eine Nachricht auf die Konsole schreibt.</p> </li> <li>Der Container beendet sich sofort danach, da er seine Aufgabe erf\u00fcllt hat.</li> </ul> <p>Wenn alles erfolgreich installiert wurde, sollte die Ausgabe in etwa so aussehen:</p> <p></p> <p>Wenn man nun im Docker Desktop nachschaut, dann sieht man unter \"Images\" pl\u00f6tzlich einen neuen Eintrag. Der Eintrag <code>hello-world</code> erscheint als heruntergeladenes Image in der Liste. Dieses Image wurde automatisch aus Docker Hub geladen, als der Befehl <code>docker run hello-world</code> ausgef\u00fchrt wurde.</p> <p></p> <p>Das bedeutet: Docker speichert dieses Image lokal, damit man es erneut verwenden kann \u2013 ohne es nochmal herunterzuladen. Man kann dieses Image auch manuell l\u00f6schen, wenn es nicht mehr ben\u00f6tigt wird, z.B. \u00fcber das Papierkorb-Symbol in Docker Desktop oder \u00fcber das Terminal mit:</p> <pre><code>docker rmi hello-world\n</code></pre> <p>Es kann sein das folgender Fehler erscheint:</p> <p></p> <p>Dann blockiert Docker das L\u00f6schen, weil es noch einen Container gibt, der mit diesem Image erstellt wurde \u2013 selbst wenn der Container gestoppt ist. Ein Docker Container wird immer aus einem Image erstellt. Man kann sich das so vorstellen:</p> <ul> <li> <p>Das Image ist der Bauplan oder die Vorlage.</p> </li> <li> <p>Der Container ist das laufende oder gespeicherte Exemplar, das daraus gebaut wurde.</p> </li> </ul> <p>Solange mindestens ein Container existiert, der auf dieses Image verweist, erlaubt Docker aus Sicherheitsgr\u00fcnden kein L\u00f6schen des Images.   In Docker Desktop gibt es links ein Men\u00fc. Dort findet man unter \"Containers\" eine Liste aller Container:</p> <p></p> <p>Hier sieht man einen Eintrag mit dem Namen <code>hello-world</code> und genau diesen Container m\u00f6chten wir entfernen, um das <code>hello-world</code> Image zu l\u00f6schen. Wir tun dies \u00fcber das Terminal mit den folgenden Befehl:</p> <pre><code>docker container rm [CONTAINER-ID]\n</code></pre> <p>Achtet darauf dass ihr die <code>[CONTAINER-ID]</code> durch eine Zahl ersetzt. Anschlie\u00dfend sollte dieser Container aus der Liste unter \"Containers\" verschwinden. Nun k\u00f6nnen wir das <code>hello-world</code> Image entfernen:</p> <pre><code>docker rmi hello-world\n</code></pre> <p></p> <p>Unter Images d\u00fcrfte nun kein Image mit dem Namen <code>hello-world</code> vorhanden sein. Damit bleibt die lokale Umgebung sauber und \u00fcbersichtlich.</p>"},{"location":"content/docker_windows_installation/#ubungsaufgabe-wiederholung-windows-installation-und-hello-world","title":"\u00dcbungsaufgabe: Wiederholung Windows-Installation und Hello World","text":"<p>Bearbeite die folgenden Schritte und beantworte die Fragen. F\u00fchre die Befehle in CMD oder PowerShell aus.</p> Windows-Installation \u2014 Wiederholung <p>Bearbeite die folgenden Schritte und beantworte die Fragen. F\u00fchre die Befehle in CMD oder PowerShell aus.</p> <p>1) System/WSL pr\u00fcfen</p> <ul> <li> <p>F\u00fchre <code>wsl</code> aus. Was wird ausgegeben? Ist WSL vorhanden?</p> </li> <li> <p>Falls nicht vorhanden: Welcher Befehl installiert WSL? (Hinweis: <code>wsl --install</code>)</p> </li> <li> <p>Pr\u00fcfe deine Windows-Version mit <code>winver</code>. Welche Version ist installiert?</p> </li> </ul> <p>2) Hello-World testen</p> <ul> <li>F\u00fchre <code>docker run hello-world</code> aus und beschreibe in 2\u20133 S\u00e4tzen, was dabei passiert (Download des Images, Start eines Containers, Ausgabe, automatisches Beenden).</li> </ul> <p>3) Pr\u00fcfen, was angelegt wurde</p> <ul> <li> <p>Zeige alle Images: <code>docker image ls</code> \u2013 ist <code>hello-world</code> vorhanden?</p> </li> <li> <p>Zeige alle Container (auch gestoppte): <code>docker ps -a</code> \u2013 siehst du einen Container aus <code>hello-world</code>?</p> </li> </ul> <p>4) Aufr\u00e4umen: Container entfernen</p> <ul> <li> <p>Entferne den erzeugten Container: <code>docker container rm &lt;CONTAINER-ID&gt;</code> (Hinweis: ID aus <code>docker ps -a</code>)</p> </li> <li> <p>Erkl\u00e4re kurz, warum man das Image oft nicht l\u00f6schen kann, solange noch ein Container darauf verweist.</p> </li> </ul> <p>5) Aufr\u00e4umen: Image entfernen</p> <ul> <li> <p>Entferne das Image: <code>docker rmi hello-world</code></p> </li> <li> <p>Pr\u00fcfe erneut mit <code>docker image ls</code>, ob es weg ist.</p> </li> </ul> Windows-Installation \u2014 Fehler im Code finden <p>Im folgenden Konsolenprotokoll haben sich Fehler eingeschlichen. Finde sie und schreibe die korrigierten Befehle auf.</p> <pre><code># Setup und Hello World testen\nwsl --instal\nwinver\ndocker pull hello world\ndocker run -d hello-world\ndocker ps --all\ndocker container rm hello-world\ndocker image rm hello_world\n</code></pre> L\u00f6sung <p>Korrekturen und kurze Begr\u00fcndung:</p> <pre><code># WSL installieren (falls n\u00f6tig) \u2013 Schreibfehler korrigiert\nwsl --install\n\n# Windows-Version pr\u00fcfen (Dialog) \u2013 korrekt, kein Docker-Befehl\nwinver\n\n# Image-Namen mit Bindestrich, nicht mit Leerzeichen\ndocker pull hello-world\n\n# Hello-World braucht kein -d, einmalig ausf\u00fchren reicht\ndocker run hello-world\n\n# Schalter ist -a, nicht --all\ndocker ps -a\n\n# Container mit ID/Name entfernen, nicht das Image\ndocker container rm &lt;CONTAINER-ID&gt;\n\n# Danach kann das Image entfernt werden\ndocker rmi hello-world\n</code></pre> Windows-Installation - Docker-Befehle zuordnen <p>Ordne die folgenden Docker-Befehle der passenden Bedeutung (A-F) zu. Die Reihenfolge ist absichtlich gemischt.</p> <p>Befehle:</p> <ul> <li> <p>docker container rm  <li> <p>docker rmi hello-world</p> </li> <li> <p>docker ps -a</p> </li> <li> <p>docker version</p> </li> <li> <p>docker image ls</p> </li> <li> <p>docker run hello-world</p> </li> <p>Bedeutungen:</p> <p>A. Zeigt Client/Server-Versionen (CLI/Engine)</p> <p>B. Startet einen Container aus einem Image und fuehrt dessen Standardprogramm aus</p> <p>C. Listet lokale Images</p> <p>D. Listet Container (auch gestoppte)</p> <p>E. Loescht ein lokales Image</p> <p>F. Entfernt einen Container</p> L\u00f6sung <p>Zuordnung:</p> <ul> <li>docker version -&gt; A</li> <li>docker run hello-world -&gt; B</li> <li>docker image ls -&gt; C</li> <li>docker ps -a -&gt; D</li> <li>docker rmi hello-world -&gt; E</li> <li>docker container rm  -&gt; F"},{"location":"content/host/","title":"Image zu Docker Hub pushen &amp; bei Render hosten (mit Beispiel-Dateien)","text":"<p>Im Folgenden bekommst du eine komplette Schritt-f\u00fcr-Schritt-Anleitung inkl. Beispiel-<code>Dockerfile</code> und <code>index.html</code> f\u00fcr eine kleine statische Website \u00fcber Nginx. Du kannst die Snippets 1:1 \u00fcbernehmen.</p>"},{"location":"content/host/#0-projektstruktur","title":"0) Projektstruktur","text":"<p>Lege einen neuen Ordner an, z. B. <code>meine-website/</code>, mit folgendem Inhalt:</p> <pre><code>meine-website/\n\u251c\u2500 Dockerfile\n\u251c\u2500 index.html\n</code></pre>"},{"location":"content/host/#1-dateien-dockerfile-indexhtml","title":"1) Dateien: <code>Dockerfile</code> &amp; <code>index.html</code>","text":"<p>Kopiere den folgenden Inhalt in die Dateien:</p>"},{"location":"content/host/#dockerfile","title":"<code>Dockerfile</code>","text":"<pre><code>FROM nginx:alpine\n\nCOPY index.html /usr/share/nginx/html/index.html\n\nRUN chown nginx:nginx /usr/share/nginx/html/index.html\n</code></pre>"},{"location":"content/host/#indexhtml","title":"<code>index.html</code>","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n&lt;style&gt;\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: Tahoma, Verdana, Arial, sans-serif; }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Willkommen auf meiner ersten Webseite!&lt;/h1&gt;\n\nIch bin ja so froh, endlich Docker zu lernen.\n\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"content/host/#2-anmeldung-bei-docker-hub","title":"2) Anmeldung bei Docker Hub","text":"<ol> <li>\u00d6ffne  hub.docker.comund erstelle ein Konto (oder einloggen).</li> <li>Lege ein Repository an: Hub \u2192 Repositories \u2192 Create Repository </li> <li>Name: <code>meine-website</code> </li> <li>Visibility: Public (oder Private, dann sp\u00e4ter Token bei Render hinterlegen)</li> </ol>"},{"location":"content/host/#3-image-lokal-bauen-zu-docker-hub-pushen","title":"3) Image lokal bauen &amp; zu Docker Hub pushen","text":"<p>\u00d6ffne eine Kommandozeile in deinem Ordner <code>meine-website</code> und f\u00fchre die folgenden Befehle aus.</p> <p>Baue zun\u00e4chst das Image:</p> <pre><code>docker build -t meine-website:1.0 .\n</code></pre> <p>Baue lokal den Container uns starte ihn, um ihn zu testen:</p> <pre><code>docker run --rm -p 8080:80 meine-website:1.0\n</code></pre> <p>Um zu pr\u00fcfen, ob deine Container einwandfrei l\u00e4uft, kannst du http://localhost:8080 im Browser \u00f6ffnen.</p> <p>Melde dich nun bei Docker Hub an, indem du in die Kommandozeile eingibst:</p> <pre><code>docker login\n</code></pre> <p>Damit das hochladen des Images auf Docker Hub korrekt funktioniert, muss du dem Image ein spezielles Tag geben. Dies kannst du wie folgt tun. </p> <p>\u26a0 Ersetze <code>DEINUSER</code> unten durch deinen Docker-Hub-Benutzernamen (z. B. <code>viktorreichert</code>)</p> <pre><code>docker tag meine-website:1.0 DEINUSER/meine-website:1.0\n</code></pre> <p>Du kannst nun dein Image auf Docker Hub uploaden mit dem folgenden Befehl:</p> <pre><code>docker push DEINUSER/meine-website:1.0\n</code></pre> <p>\u26a0 Wenn der Upload nicht erlaubt wird, melde dich von Docker Hub ab</p> <pre><code>docker logout\n</code></pre> <p>und danach wieder an.</p> <pre><code>docker login\n</code></pre> <p>Dann sollte der Upload funktionieren.</p> <p>Gehe auf dein Repository im Docker Hub (dr\u00fccke ggf. <code>F5</code>) und du solltest das hochgeladene Image sehen.</p>"},{"location":"content/host/#4-anmeldung-bei-render","title":"4) Anmeldung bei Render","text":"<ol> <li>\u00d6ffne  https://render.com und registriere dich (GitHub/GitLab/E-Mail).</li> <li>Free-Plan reicht f\u00fcr Tests.</li> </ol>"},{"location":"content/host/#5-docker-image-bei-render-hosten-web-service","title":"5) Docker-Image bei Render hosten (Web Service)","text":"<ol> <li>Dashboard \u2192 New + \u2192 Web Service</li> <li>Deploy an existing image from a registry w\u00e4hlen.</li> <li>Registry: Docker Hub </li> <li>Falls privat: Docker-Hub-Login/Access-Token hinterlegen.</li> <li>Image URL: <pre><code>DEINUSER/meine-website:1.0\n</code></pre>    (optional vollqualifiziert: <code>docker.io/DEINUSER/meine-website:1.0</code>)</li> <li>Region: EU-Region (z. B. Frankfurt), Service Type: Web Service, Instance Type/Plan: nach Bedarf (Free f\u00fcr Tests).</li> <li>Port: <code>80</code> (Nginx bedient Port 80 im Container).</li> <li>Create Web Service \u2192 Render zieht das Image und startet den Container.</li> <li>Nach dem Deploy bekommst du eine \u00f6ffentliche URL, z. B. <code>https://meine-website.onrender.com</code></li> </ol> <p>Fertig! Damit hast du eine statische Seite via Nginx als Docker-Image auf Docker Hub und hostest dieses Image als Web Service bei Render.</p>"},{"location":"content/intro_docker/","title":"Einf\u00fchrung in Docker","text":"<p>Um besser zu verstehen, was genau Docker ist, sollte man sich vorher mit physischen Servern und virtuellen Maschinen auseinandersetzen.</p>"},{"location":"content/intro_docker/#physischer-server","title":"Physischer Server","text":"<p>Ein physikalischer Server ist im Grunde genommen ein gro\u00dfer, leistungsstarker Computer. Dieser computer hat eine eigene Hardware, die aus Komponenten wie Haupt-Prozessor (CPU), Arbeitsspeicher (RAM), Festplatten und Netzwerkschnittstellen besteht. Au\u00dferdem ist in fast allen F\u00e4llen ein Betriebssystem vorhanden, um das Zusammenspiel der Hardwarekomponenten mit der Software, durch eine \"sch\u00f6ne\" Oberfl\u00e4che zu erm\u00f6glichen.</p> <p></p> <p>Physikalische Server befinden sich oft in Rechenzentren, wo sie spezielle Aufgaben erf\u00fcllen, wie z.B. das Hosten von Websites, das Speichern von Datenbanken oder das Ausf\u00fchren von Anwendungen. Dies ist der traditionelle Weg, wie Softwareingenieure die programmierten Anwendungen ausf\u00fchrten bzw. entwickelt hatten.</p> <p>So k\u00f6nnte ein Rechenzentrum mit Servern aussehen:</p> <p></p> <p>Man kann die physischen Server auch in verschiedene Kategorien unterteilen wie z.B.:</p> <ul> <li> <p>Web-Server</p> </li> <li> <p>Proxy-Server</p> </li> <li> <p>FTP-Server</p> </li> <li> <p>Datenbank-Server</p> </li> <li> <p>Druckserver</p> </li> </ul> <p>Traditionell wird diese Software auf physischen Servern entwickelt bzw. auch bereitgestellt. Der Ablauf k\u00f6nnte folgenderma\u00dfen aussehen:</p> <ol> <li>Entwickler arbeiten zun\u00e4chst auf ihren lokalen Maschinen, um den Code zu schreiben und grundlegende Tests durchzuf\u00fchren. F\u00fcr komplexere Tests richteten sie Entwicklungsumgebungen auf physischen Servern ein, welche die Produktionsumgebung nachahmten.</li> <li>Nach der Entwicklung wurde die Software auf Testservern bereitgestellt, die ebenfalls physische Server waren. Hier wurden verschiedene Tests durchgef\u00fchrt, wie z.B. Integrationstests und Systemtests, um sicherzustellen, dass sie Software korrekt funktionierte.</li> <li>Vor dem endg\u00fcltigen Rollout (ausliefern der Software) wurde die Software auf Staging-Servern installiert. Diese physischen Server bildeten die Produktionsumgebung so genau wie m\u00f6glich nach, um letzte \u00dcberpr\u00fcfungen und Tests unter realistischen Bedingungen durchzuf\u00fchren.</li> <li>Sobald die Software alle Tests bestanden hatte, wurde sie auf den Produktionsservern bereitgestellt. Diese physischen Server waren daf\u00fcr verantwortlich, die Software f\u00fcr die Endbenutzer bereitzustellen und zu betreiben.</li> <li>Nach der Bereitstellung \u00fcberwachten Entwickler und IT-Teams die Serverleistung, f\u00fchrten regelm\u00e4\u00dfige Wartungsarbeiten durch und rollten bei Bedarf Updates und Patches aus, um die Software aktuell und sicher zu halten.</li> </ol> <p></p> <p>Diese Prozesse sind jedoch sehr zeitaufw\u00e4ndig und erfordern eine sorgf\u00e4ltige Planung und Verwaltung der physischen Serverressourcen.</p>"},{"location":"content/intro_docker/#virtuelle-maschinen-vms","title":"Virtuelle Maschinen (VMs)","text":"<p>Nach dem die Grundlagen physischer Server und ihre Rolle in der traditionellen Softwareentwicklung verstanden wurde, werden wir uns einem moderneren Konzept wenden: Den virtuellen Maschinen.   Virtuelle Maschinen haben die Art und Weise, wie wir Serverressourcen nutzen, revolutioniert und bieten viele Vorteile gegen\u00fcber physischen Servern. Eine virtuelle Maschine (VM) ist im Wesentlichen ein Software-Emulator, der wie ein eigenst\u00e4ndiger Computer funktioniert. Ein Software-Emulator ist ein Programm, dass die Hardware eines Computers nachahmt und es erm\u00f6glicht, Software so auszuf\u00fchren, als w\u00fcrde sie auf der tats\u00e4chlichen Hardware laufen.  </p> <p>Zur Vorstellung eines Software-Emulators ein Beispiel:</p> <p>Stellt euch vor, ihr habt ein altes Nintendo-Spiel, das ihr fr\u00fcher auf einer Nintendo-Konsole gespielt habt. Jetzt habt ihr keine Konsole mehr, sondern nur noch den Computer. Ihr m\u00f6chtet das alte Spiel trotzdem spielen. Hier kommt der Emulator zum Einsatz. Ihr ladet euch ein Emulator-Programm auf den Computerherunter, das die Nintendo-Konsole nachahmt. Ihr ladet auch das Nintendo-Spiel auf den Computer. Anschlie\u00dfend startet ihr den Emulator und \u00f6ffnet das Spiel darin. Der Emulator verh\u00e4lt sich wie eine Nintendo-Konsole. Euer Computer denkt, er w\u00e4re die Konsole, und das Spiel denkt, es w\u00fcrde auf der echten Nintendo-Konsole laufen. So k\u00f6nnt ihr das Nintendo-Spiel auf euerem Computer spielen, obwohl es eigentlich f\u00fcr die Konsole gedacht ist.</p> <p></p> <p>Zur\u00fcck zu dem VMs:</p> <p>Eine VM (sowas wie ein Software-Emulator) l\u00e4uft auf einem physischen Server, nutzt dessen Ressourcen, wird aber durch eine Software namens Hypervisor verwaltet. Der Hypervisor erm\u00f6glicht es, mehrere VMs auf einem einzigen physischen Server zu betreiben, wobei jede VM ein eigenes Betriebssystem und eigene Anwendungen haben kann, unabh\u00e4ngig von den anderen VMs auf demselben Server.   Man kann sich der Hypervisor wie einen Verwalter vorstellen, der die Ressourcen eines Computers so aufteilt, dass mehrere unabh\u00e4ngige VMs gleichzeitig laufen k\u00f6nnen.</p> <p>Hypervisor: Teilt Ressourcen des Host-Servers auf mehrere isolierte VMs auf.</p> <p></p> <p>Die moderne Softwareentwicklung auf VMs, hat sich stark von der traditionellen Entwicklung auf physischen Servern weiterentwickelt. Angenommen, ein Softwareunternehmen entwickelt eine Webanwendung:</p> <ol> <li>Die Entwickler verwenden jeweils eine eigene VM, um verschiedene Komponenten der Anwendung zu entwickeln und zu testen. Jede VM ist mit den erforderlichen Entwicklungswerkzeugen und Bibliotheken ausgestattet.</li> <li>QA-Teams f\u00fchren Tests auf speziell eingerichteten VMs durch, um die Funktionalit\u00e4t, Sicherheit und Leistung der Anwendung zu \u00fcberpr\u00fcfen. Sie k\u00f6nnen verschiedene Szenarien simulieren und sicherstellen, dass die Anwendung unter verschiedenen Bedingungen einwandfrei funktioniert.</li> <li>Vor der endg\u00fcltigen Bereitstellung wird die Anwendung auf einer Staging-VM getestet, die der Produktivumgebung \u00e4hnelt. Nach erfolgreichen Tests wird die Anwendung auf die Produktions-VMs bereitgestellt, welche die eigentliche Anwendung f\u00fcr Endbenutzer hosten.</li> </ol> <p></p> <p>Durch die VMs hat man bei der Softwareentwicklung eine Menge von Vorteilen:</p> <ol> <li>Flexibilit\u00e4t: VMs erm\u00f6glichen es Entwicklern, schnell und einfach verschiedene Entwicklungsumgebungen einzurichten und zu nutzen. Jede VM kann ein eigenes Betriebssystem und eine eigene Konfiguration haben, was es einfach macht, verschiedene Softwareversionen und -stacks zu testen-</li> <li>Isolation: Jede VM ist isoliert von anderen VMs und der zugrundeliegenden Hardware. Das bedeutet, dass \u00c4nderungen oder Probleme in einer VM die anderen nicht beeintr\u00e4chtigen. Dies erleichtert das Testen und die Entwicklung von Software in einer kontrollierten Umgebung.</li> <li>Skalierbarkeit: Unternehmen k\u00f6nnen ihre Serverressourcen effizienter nutzen, indem sie mehrere VMs auf weniger physischen Servern betreiben. Dies em\u00f6glicht es, schnell neue VM-Instanzen zu erstellen oder bestehende zu entfernen, je nach Bedarf.</li> <li>Schnelle Bereitstellung: VMs k\u00f6nnen schnell bereitgestellt werden, was den Entwicklungszyklus beschleunigt. Neue VMs k\u00f6nnen in wenigen Minuten einsatzbeareit sein, im Gegensatz zu physischen Servern, die m\u00f6glicherweise Tage oder Wochen zur Bereitstellung ben\u00f6tigen.</li> <li>Reproduzierbarkeit: Da VMs als Images (Momentaufnahme eines kompleten Software-Systems) gespeichert werden k\u00f6nnen, ist es einfach, eine bestimmte Entwicklungsumgebung zu sichern, zu klonen oder wiederherzustellen. Dies erleichtert die Reproduktion von Fehlern und die \u00dcberpr\u00fcfung von Software in verschiedenen Umgebungen.</li> <li>Kosteneffizienz: Durch die Konsolidierung (Zusammenf\u00fchren) mehrerer VMs auf weniger Hardware k\u00f6nnen Unternehmen Kosten sparen, da weniger physische Server ben\u00f6tigt werden. Auch die Wartung und Verwaltung der Infrastruktur wird vereinfacht.</li> </ol> <p>Um die Vorteile von Docker zu verstehen, setzen wir unsere Reise von physischen Servern und virtuellen Maschinen fort. Virtuelle Maschinen haben die Flexibilit\u00e4t und Effizient in der Softwareentwicklung erh\u00f6ht, aber Docker geht noch einen Schritt weiter.</p>"},{"location":"content/intro_docker/#was-ist-docker","title":"Was ist Docker","text":"<p>Docker ist eine Plattform, die es erm\u00f6glicht, Anwendungen und deren Abh\u00e4ngigkeiten (z.B. Bibliotheken, Datenbanken oder Laufzeitumgebungen...) in sogenannten Containern zu verpacken. Ein Docker-Container ist eine Art isolierte Umgebung, die alle notwendigen Bibliotheken und Konfigurationen enth\u00e4lt, um eine Anwendung auszuf\u00fchren.   Anders als bei virtuellen Maschinen nutzen Docker-Container den gleichen Kernel (das Herzst\u00fcck) des Betriebssystems, auf dem sie laufen. Das bedeutet, dass Docker-Container nicht wie virtuelle Maschinen ihr eigenes komplettes Betriebssystem haben. Stattdessen teilen sie sich den zentralen Teil des Betriebssystems, der direkt mit der Hardware des Computers kommuniziert.   Diese gemeinsame Nutzung macht Docker-Container effizienter, da sie weniger Ressourcen ben\u00f6tigen und schneller starten k\u00f6nnen im Vergleich zu virtuellen Maschinen, die jedes Mal eine komplette Kopie des Betriebssystems mitbringen m\u00fcssen.</p> <p></p> <p>Bildhafte Vorstellung:</p> <p>Falls man bei der Vorstellung bez\u00fcglich der \"Teilung des gleichen Kernels\" Schwierigkeiten hat, k\u00f6nnte folgende bildhafte Vorstellung behilflich sein:</p> <ul> <li> <p>Stellt euch vor, der Kernel des Betriebssystems ist wie ein Motor in einem Auto. Dieser Motor (Kernel) ist entscheidend, um das Auto (Computer) zum Laufen zu bringen. Bei virtuellen Maschinen ist es so, als ob jedes Auto sein eigenes Motorenset hat, komplett mit allen Teilen, die es zum Fahren ben\u00f6tigt.</p> </li> <li> <p>Bei Docker-Containern ist es anders. Alle Container teilen sich denselben Motor (Kernel) des Autos (Betriebssystems). Jeder Container hat sein eigenes Cockpit und seine eigenen Steuerungen, aber sie alle nutzen denselben Motor, um sich fortzubewegen.</p> </li> </ul> <p></p>"},{"location":"content/intro_docker/#die-docker-container","title":"Die Docker Container","text":"<p>Container basieren also auf der Idee der Virtualisierung, allerdings auf einer leichteren und effizienteren Ebene als traditionelle virtuelle Maschinen. Bei VMs wird ein komplettes Betriebssystem auf einem sogenannten Hypervisor nachgebildet. Container hingegen nutzen den gleichen Betriebssystem-Kernel, teilen sich also das Grundsystem und laufen trotzdem getrennt voneinander auf dem gleichen Computer.   Man kann sich Container wie kleine, abgeschlossene Pakete vorstellen. In einem Paket ist eine Anwendung und alles, was sie ben\u00f6tigt, enthalten. So ein Paket enth\u00e4lt zum Beispiel:</p> <ul> <li> <p>Den Programmcode</p> </li> <li> <p>Alle notwendigen Programme und Bibliotheke, die das Programm ben\u00f6tigt</p> </li> <li> <p>Einstellungen und Konfigurationen</p> </li> </ul>"},{"location":"content/intro_docker/#warum-container","title":"Warum Container?","text":"<p>Ihr m\u00f6chtet ein Programm auf einem anderen Computer ausf\u00fchren, aber dort fehlen einige notwendige Programme oder die Einstellungen sind anders, Das f\u00fchrt oft zu Problemen und Fehlern.   Mit Docker packt ihr das Programm und alles, was es braucht, in ein Container. Dieser Container l\u00e4uft \u00fcberall gleich, egal auf welchem Computer oder Betriebssystem, solange Docker oder eine \u00e4hnliche Container-Technologie installiert ist.</p> <p>Beispiel:</p> <p>Stellt euch vor, drei Entwickler arbeiten an einer Webanwendung. Jeder von ihnen benutzt ein anderes Betriebssystem:</p> <ol> <li>Anna arbeitet auf einem Max.</li> <li>Ben nutzt Windows</li> <li>Calra verwendet Linux</li> </ol> <p>Die Entwickler m\u00fcssen sicherstellen, dass die Webanwendung auf allen Betriebssystemen einwandfrei funktioniert, was oft zu Problemen f\u00fchrt, weil jede Plattform unterschiedliche Abh\u00e4ngigkeiten und Konfigurationen ben\u00f6tigt. Ohne Docker m\u00fcsste jeder entwickler sicherstellen, dass alle notwendigen Programme und Bibliotheken auf seinem Betriebssystem korrekt installiert sind. Das kann zu Kompatibilit\u00e4tsproblemen f\u00fchren und viel Zeit kosten.  </p> <p>Jetzt kommt Docker ins Spiel. Statt sich um die Installation und Konfiguration der Abh\u00e4ngigkeiten auf jedem Betriebssystem zu k\u00fcmmern, packen die Entwickler die Webanwendung in einem Docker-Container. Dieser Container enth\u00e4lt alles, was die Anwendung zum Laufen ben\u00f6tigt:</p> <ul> <li> <p>Den Webserver</p> </li> <li> <p>Die Laufzeitumgebung</p> </li> <li> <p>Bibliotheken</p> </li> <li> <p>Einstellungen</p> </li> </ul> <p>Egal ob Anna, Ben oder Clara, alle m\u00fcssen nur Docker auf ihrem System installieren. Dann k\u00f6nnen sie den Container ausf\u00fchren und die Anwendung l\u00e4uft \u00fcberall gleich, unabh\u00e4ngig davon, welches Betriebssystem sie benutzen. Der Container sorgt daf\u00fcr, dass die Anwnedung in einer identischen Umgebung l\u00e4uft, unabh\u00e4ngig davon, ob es ein Mac, Windows oder Linux ist.   Zusammengefasst: Mit Docker spielt es keine Rolle, welches Betriebssystem die Entwickler benutzen, weil der Container die gesamte notwendige Umgebung f\u00fcr die Anwendung mitbringt und \u00fcberall gleich funktionieren. Daraus ergeben sich folgende Unterschiede f\u00fcr physische Server, VMs und Container:</p> Aspekt Physischer Server VM Container Isolation Jeder Server ist vollst\u00e4ndig isoliert Jede VM ist isoliert, teilt jedoch denselben Hypervisor Jeder Container ist isoliert, teilt aber den Kernel Ressourcen Hat exklusive Hardware-Ressourcen Zwischen VMs aufgeteilt Effizientere Nutzung durch Kernel-Teilung Performance Hohe Leistung, direkter Zugriff auf Hardware Geringf\u00fcgige Leistungseinbu\u00dfen durch Hypervisor Sehr geringe Leistungseinbu\u00dfen da (kein Betriebssystem) Skalierbarkeit Erfordert physische Hardware\u00e4nderungen Flexibel durch Hinzuf\u00fcgen/Entfernen von VMs Sehr schnelle Skalierung durch Starten/Stoppen von Containern Portabilit\u00e4t Nicht m\u00f6glich wegen physischer Hardware Zwischen unterschiedlichen Hypervisoren Sehr portabel auf verschiedenen Umgebungen Startzeit Sehr Langsam (kann Minuten dauern) Schneller als physische Server Sekundenschnell (am schnellsten) Isolationsstufe Hohe Isolation Mittlere Isolation zwischen VMs Isoliert, bis auf Kernel Komplexit\u00e4t Je nach Anwendung (oft schwierig wegen Hardware) Komplexe Verwaltung von mehreren VMs und Hypervisoren Sehr einfache Verwaltung von Containern Entwicklungsgeschwindigkeit Langsame Bereitstellung und Entwicklung Schneller als bei physischen Servern Am schnellsten Anwendungsbereiche Spezialisierte dauerhafte Workloads Vielseitig f\u00fcr z.B. Testumgebung Ideal f\u00fcr Cloud, Microservices, DevOps... <p>In der Praxis arbeiten Data Engineers mit vielen verschiedenen Tools, Programmiersprachen, Frameworks und Datenquellen \u2013 etwa Python, Spark, Kafka, Airflow, Datenbanken wie PostgreSQL oder MongoDB sowie Cloud-Speicherdiensten. Jedes dieser Systeme hat eigene Abh\u00e4ngigkeiten, Versionen und Konfigurationen. Hier kommt Docker ins Spiel.   Docker erm\u00f6glicht es, Container zu erstellen \u2013 also abgeschlossene, isolierte Software-Umgebungen, in denen eine bestimmte Anwendung samt aller n\u00f6tigen Komponenten (Code, Bibliotheken, Laufzeitumgebung, Einstellungen) enthalten ist. So kann ein Data Engineer beispielsweise einen Container bauen, der einen bestimmten ETL-Prozess (Extract, Transform, Load) ausf\u00fchrt \u2013 unabh\u00e4ngig vom Betriebssystem oder den installierten Tools auf dem Server oder Entwicklerrechner. Das macht die Umgebung reproduzierbar und plattformunabh\u00e4ngig.   Jeder Schritt im Datenverarbeitungsprozess kann in einem eigenen Container ablaufen \u2013 zum Beispiel die Datenextraktion aus einer API, die Bereinigung mit Python oder Spark, und schlie\u00dflich das Laden in eine Datenbank oder ein Data Warehouse. Diese Container k\u00f6nnen unabh\u00e4ngig voneinander entwickelt, getestet und ausgetauscht werden. Das erh\u00f6ht die Flexibilit\u00e4t und Wartbarkeit der gesamten Pipeline.   Zusammengefasst ist Docker ein unverzichtbares Werkzeug im modernen Data Engineering, weil es hilft, Prozesse zu vereinfachen, zu standardisieren und \u00fcber Systemgrenzen hinweg reproduzierbar zu machen</p>"},{"location":"content/layers/","title":"Docker Layers \u2013 Wie Docker Images wirklich aufgebaut sind","text":"<p>Beim Erstellen eigener Docker-Images mit einem Dockerfile haben wir gesehen, dass ein Image aus mehreren Befehlen entsteht \u2013 zum Beispiel FROM, COPY, RUN oder CMD. Was viele nicht wissen: Jeder dieser Befehle erzeugt eine sogenannte Layer (Schicht) im Image.   Dieses Layer-Konzept ist ein zentraler Bestandteil von Docker. Es hilft dabei:</p> <ul> <li> <p>Images effizient zu speichern,</p> </li> <li> <p>wiederverwendbare Teile zwischen Builds zu cachen,</p> </li> <li> <p>und kleinere \u00c4nderungen blitzschnell zu \u00fcbernehmen.</p> </li> </ul>"},{"location":"content/layers/#was-sind-layers","title":"Was sind Layers","text":"<p>Ein Layer (auf Deutsch: Schicht) ist ein Baustein, aus dem ein Docker-Image zusammengesetzt ist.</p> <p>Man kann sich das vorstellen wie bei einer Lasagne:</p> <ul> <li> <p>Jede einzelne Zutat wird Schicht f\u00fcr Schicht aufgetragen \u2013 am Ende ergibt alles zusammen das vollst\u00e4ndige Gericht.</p> </li> <li> <p>Genauso entsteht auch ein Docker-Image Schritt f\u00fcr Schritt \u2013 jede Zeile im Dockerfile ist eine neue Schicht, also ein Layer.</p> </li> </ul> <p>Ein Layer ist eine Momentaufnahme einer \u00c4nderung im Dateisystem. Das bedeutet: Immer wenn im Dockerfile eine neue Anweisung steht, merkt sich Docker nur das, was sich ver\u00e4ndert hat. Die vorherigen Schichten bleiben unver\u00e4ndert bestehen.   Schauen wir uns ein konkretes Beispiel an:</p> <pre><code>FROM python:3.12-slim                # Layer 1: Basis-Image mit Python\nWORKDIR /app                         # Layer 2: Wechselt ins Arbeitsverzeichnis /app\nCOPY requirements.txt .              # Layer 3: requirements.txt wird ins Image kopiert\nRUN pip install -r requirements.txt  # Layer 4: Python-Pakete werden installiert\nCOPY . .                             # Layer 5: Quellcode wird ins Image kopiert\nCMD [\"python\", \"main.py\"]            # Layer 6: Startbefehl f\u00fcr den Container\n</code></pre> <ul> <li> <p>Layer 1:   Docker l\u00e4dt ein fertiges Python-Image aus dem Docker Hub, das ist die Grundlage.</p> </li> <li> <p>Layer 2:   Es wird ein Ordner namens /app als Arbeitsverzeichnis gesetzt. Ab jetzt spielen sich alle weiteren Schritte dort ab.</p> </li> <li> <p>Layer 3:   Eine Datei <code>requirements.txt</code> wird vom eigenen Rechner ins Image kopiert.</p> </li> <li> <p>Layer 4:   Alle dort aufgelisteten Pakete werden installiert. Das kann z.\u202fB. flask, numpy, requests usw. sein.</p> </li> <li> <p>Layer 5:   Der restliche Quellcode wird ebenfalls ins Image \u00fcbernommen.</p> </li> <li> <p>Layer 6:   Es wird festgelegt, was passiert, wenn man den Container startet (hier: Python-Programm ausf\u00fchren).</p> </li> </ul> <p>Jeder dieser Schritte wird einzeln gespeichert \u2013 als eine eigene Schicht. Wenn man sp\u00e4ter etwas am Dockerfile \u00e4ndert, muss nicht alles neu gebaut werden \u2013 nur die betroffenen Layers.   Betrachten wir die Layers von unserem selbst erstellten <code>mysite</code>-Image. Dazu klicken wir im Docker Desktop auf den <code>mysite</code>-Image und sehen direkt die Layers:</p> <p></p> <p>Docker merkt sich beim Bauen, welche Layers bereits existieren. Wenn man das Dockerfile ein zweites Mal baut, muss Docker nicht alles neu berechnen, sondern kann bestehende Schichten aus dem Cache \u00fcbernehmen. Wenn man am z.B. Quellcode Layer 5 etwas \u00e4ndert, bleibt Layer 3 und 4 unver\u00e4ndert und k\u00f6nnen aus dem Cache \u00fcbernommen werden. Das spart enorm viel Zeit. Als Faustregel kann man sich merken:</p> <ul> <li>Je fr\u00fcher eine \u00c4nderung im Dockerfile, desto mehr Layers m\u00fcssen neu gebaut werden. Deshalb sollte man m\u00f6glichst unver\u00e4nderliche Befehle zuerst schreiben.</li> </ul>"},{"location":"content/layers/#sicherheitsaspekt-von-layers","title":"Sicherheitsaspekt von Layers","text":"<p>Beim Umgang mit Docker ist es besonders wichtig, die Sicherheit der erstellten Images zu ber\u00fccksichtigen. Ein zentrales Konzept in diesem Zusammenhang ist die Unver\u00e4nderlichkeit von Layers \u2013 und welche Folgen das f\u00fcr sensible Daten wie Passw\u00f6rter, Zugangsschl\u00fcssel oder Konfigurationsdateien hat.   Ein grundlegendes Prinzip von Docker ist:</p> <ul> <li>Jeder Layer ist eine feste, unver\u00e4nderbare Momentaufnahme des Dateisystems.</li> </ul> <p>Wenn also ein Befehl im Dockerfile eine Datei erzeugt \u2013 etwa eine Textdatei mit Passw\u00f6rtern \u2013 dann wird diese Datei dauerhaft in diesem Layer gespeichert. Selbst wenn sie in einem sp\u00e4teren Schritt wieder gel\u00f6scht wird, verschwindet sie nicht wirklich aus dem Image.   Stellen wir uns folgendes Dockerfile vor:</p> <pre><code>FROM python:3.12-slim\n\n# Hier liegt das Problem: Die Datei enth\u00e4lt ein geheimes Token\nCOPY secrets.txt /tmp/secrets.txt\n\n# Sp\u00e4ter wird die Datei gel\u00f6scht\nRUN rm /tmp/secrets.txt\n\nCMD [\"python\", \"main.py\"]\n</code></pre> <p>Auf den ersten Blick scheint das korrekt:</p> <ul> <li> <p>Die Datei secrets.txt wird eingebunden</p> </li> <li> <p>Danach direkt wieder gel\u00f6scht</p> </li> </ul> <p>Doch technisch passiert Folgendes:</p> <ul> <li> <p>Layer 1: Basierend auf python:3.12-slim</p> </li> <li> <p>Layer 2: secrets.txt wird in das Image geschrieben</p> </li> <li> <p>Layer 3: secrets.txt wird gel\u00f6scht, ist nur im neuen Layer nicht mehr sichtbar</p> </li> </ul> <p>Der zweite Layer \u2013 mit der Datei <code>secrets.txt</code> \u2013 bleibt dauerhaft erhalten, auch wenn sp\u00e4tere Schichten diese Datei \"unsichtbar\" machen. Ein Angreifer, der Zugriff auf dein Image hat, k\u00f6nnte mit einfachen Tools oder manuellen Extraktionen:</p> <ul> <li> <p>Das Image \"aufschneiden\"</p> </li> <li> <p>Den Layer mit der sensiblen Datei isolieren</p> </li> <li> <p>Den Inhalt der Datei wiederherstellen</p> </li> </ul> <p>Die wichtigste Regel lautet daher:</p> <ul> <li>Keine geheimen Daten ins Image einbauen \u2013 weder \u00fcber <code>COPY</code> noch \u00fcber <code>RUN echo</code> oder andere Anweisungen!</li> </ul>"},{"location":"content/persistence/","title":"Datenpersistenz in Docker","text":"<p>Wenn ein Docker-Container gestartet wird, hat er ein eigenes, isoliertes Dateisystem. Dieses Dateisystem basiert auf dem zugeh\u00f6rigen Image und wird jedes Mal beim Start neu erstellt \u2013 frisch, sauber, leer. Das bedeutet:</p> <ul> <li> <p>Alle Daten, die w\u00e4hrend der Laufzeit des Containers gespeichert werden, gehen beim Stoppen oder Neustarten verloren.</p> </li> <li> <p>Ein Webserver-Container vergisst z.\u202fB. Log-Dateien, eine Datenbank vergisst alle gespeicherten Datens\u00e4tze, und Skripte, die Dateien schreiben, starten wieder bei null.</p> </li> </ul> <p>Docker-Container sind standardm\u00e4\u00dfig fl\u00fcchtig. Um Daten dauerhaft zu speichern, ben\u00f6tigt es sogenannte Persistenzmechanismen.   In der Praxis gibt es kaum Anwendungen, die vollst\u00e4ndig ohne dauerhafte Datenspeicherung auskommen. Fast alle Anwendungen generieren Daten zur Laufzeit, die \u00fcber die Lebensdauer eines Containers hinaus erhalten bleiben m\u00fcssen.</p> <p>Betrachten wir folgendes Beispiel: </p> <ul> <li> <p><code>f = '/data.txt'</code>: Wir erstellen eine Datei <code>data.txt</code> im Wurzelverzeichnis. </p> </li> <li> <p><code>open(f, 'a').write('Ran!\\n')</code>: Die Datei <code>data.txt</code> wird im Anh\u00e4ngemodus <code>a</code> ge\u00f6ffnet \u2013 falls sie nicht existiert, wird sie erstellt. Dann wird <code>Ran! + Zeilenumbruch</code> angeh\u00e4ngt.</p> </li> <li> <p><code>print(open(f).read())</code>: \u00d6ffnet die Datei im Lesemodus (Standard) und gibt den gesamten Inhalt auf der Konsole aus</p> </li> </ul> <p>Dazu f\u00fchren wir folgenden Befehl aus:</p> <pre><code>docker run --rm python:3.12 python -c \"f='/data.txt'; open(f, 'a').write('Ran!\\n'); print(open(f).read())\"\n</code></pre> <p></p> <p>Aber egal wie oft wir diesen Befehl ausf\u00fchren, wird immer nur \"Ran!\" ausgegeben. Die <code>data.txt</code> Datei wird also nicht erweitert, weil bei jedem Container-Start alles auf den Ausgangszustand gesetzt wird:</p> <p></p> <p>Um diesem Problem zu l\u00f6sen, bietet Docker eine L\u00f6sung. Docker erlaubt es, Verzeichnisse von au\u00dfen in einen Container \"hineinzumounten\". Dadurch k\u00f6nnen Daten auch dann erhalten bleiben, wenn der Container gestoppt oder gel\u00f6scht wird. Docker kennt zwei grundlegende Mechanismen, um externen Speicher in Container einzubinden:</p> Art Beschreibung Volumes Speicherbereiche, die von Docker verwaltet werden. Diese liegen au\u00dferhalb des Containers und sind vom Host nicht direkt sichtbar, aber dauerhaft gespeichert. Bind Mounts Ein Ordner vom Hostsystem (also z.B. dein Computer) wird direkt in den Container eingebunden \u2013 z.B. der Projektordner oder eine Konfigurationsdatei."},{"location":"content/persistence/#volume-mount","title":"Volume Mount","text":"<p>Betrachten wir Volume-Mount als erstes. Wir erstellen ein Volume namens <code>mydata</code> und mounten es in den Container unter <code>/data</code>:</p> <pre><code>docker run --rm -v mydata:/data python:3.12 python -c \"f='/data/data.txt'; open(f, 'a').write('Ran!\\n'); print(open(f).read())\"\n</code></pre> <ul> <li> <p>Im Container wird die Datei <code>/data/log.txt</code> beschrieben.</p> </li> <li> <p>Bei jedem neuen Containerlauf bleibt der Inhalt erhalten, weil das Volume persistent ist.</p> </li> <li> <p><code>mydata</code> ist der Name eines Docker-Volue</p> </li> <li> <p><code>/data</code> ist das Verzeichnis im Container, in das dieses Volume eingebunden wird</p> </li> </ul> <p></p> <p>Wir k\u00f6nnten nun den Container mit einem interaktiven Terminal starten und nochmal das Volume <code>mydata</code> mounten:</p> <pre><code>docker run -it -v mydata:/data python:3.12 bash\n</code></pre> <p>Nun bekommt man ein Terminal im Container. Hier geben wir ein:</p> <pre><code>ls data\n</code></pre> <p>Hier m\u00fcsste die Datei <code>data.txt</code> liegen, wir k\u00f6nnen sie auslesen:</p> <pre><code>cat /data/data.txt\n</code></pre> <p>Das Kommando <code>cat</code> ist die Abk\u00fcrzung f\u00fcr \"concatenate\" und wird im Terminal (z.B. in Linux, macOS oder im Docker-Container) verwendet, um den Inhalt einer Datei auf der Konsole anzuzeigen.</p> <p></p> <p>Volume-Mount eignet sich hervorragend f\u00fcr persistente Datenbanken oder Cacheverzeichnisse, die unabh\u00e4ngig vom Host sind.</p>"},{"location":"content/persistence/#bind-mount","title":"Bind Mount","text":"<p>Ein Bind Mount ist ideal f\u00fcr die lokale Entwicklung, bei der Dateien vom Host in den Container gespiegelt werden sollen. Es wird also ein Ordner auf dem Host-Rechner mit einem Pfad im Container verkn\u00fcpft. Der Container greift dann direkt auf diesen Ordner zu.   Stellen wir uns vor, im aktuellen Arbeitsverzeichnis <code>C:\\Users\\olexa\\OneDrive\\Dokumente\\my_test_project</code> liegt ein einfaches Python-Skript <code>main.py</code>.</p> <p></p> <p>Das Skript soll im Container ausgef\u00fchrt werden, aber die Datei <code>log.txt</code> soll lokal im Projektverzeichnis bleiben. Wir starten den Container mit Bind-Mount:</p> <pre><code>docker run --rm -v \"C:\\Users\\olexa\\OneDrive\\Dokumente\\my_test_project:/app\" -w /app python:3.12 python main.py\n</code></pre> <ul> <li> <p><code>-v \"C:\\...:\\app\"</code> Das Verzeichnis auf deinem Host (Windows) wird in den Container unter <code>/app</code> eingebunden.</p> </li> <li> <p><code>w /app</code> Setzt das Arbeitsverzeichnis im Container auf <code>/app</code>. Alle Befehle starten dort.</p> </li> <li> <p><code>python main.py</code> F\u00fchrt im Container den Python-Interpreter aus und \u00fcbergibt ihm das Skript main.py.</p> </li> </ul> <p>Nach Ausf\u00fchrung des Befehls wird:</p> <ul> <li> <p>eine Datei <code>log.txt</code> im Windows-Ordner angelegt (falls nicht vorhanden),</p> </li> <li> <p><code>Script wurde ausgef\u00fchrt</code> hineingeschrieben,</p> </li> </ul> <p></p> <p>Man kann den Container auch interaktiv starten und sich ansehen, ob der Pfad <code>/app</code> korrekt eingebunden ist:</p> <pre><code>docker run -it -v \"C:\\Users\\olexa\\OneDrive\\Dokumente\\my_test_project:/app\" -w /app python:3.12 bash\n</code></pre> <p>Anschlie\u00dfend gibt man ein:</p> <pre><code>ls\ncat log.txt\n</code></pre> <p></p> <p>Bei einem Bind Mount handelt es sich also um eine direkte Verkn\u00fcpfung (kein Kopieren!) zwischen einem Ordner auf dem Hostsystem (z.B. ein lokaler Windows-Ordner) und einem Verzeichnis im Container. Alles, was im Container unter <code>/app</code> passiert (z.B. Datei schreiben, l\u00f6schen, editieren), passiert tats\u00e4chlich direkt im Host-Verzeichnis. Man kann sich das vorstellen wie einen gemeinsamen Ordner, den zwei Betriebssysteme gleichzeitig verwenden.   Betrachten wir folgende Grafik f\u00fcr das Verst\u00e4ndnis:</p> <p></p> <p>1. Der Container:</p> <ul> <li>Wenn in einem Container z.\u202fB. eine Datei geschrieben wird z.B. <code>log.txt</code>, ohne Bind Mount oder Volume, dann ist sie nur hier gespeichert \u2013 und geht beim L\u00f6schen des Containers verloren.</li> </ul> <p>2. Volumes:</p> <ul> <li>Dieser Ort ist perfekt f\u00fcr Produktivdatenbanken, Caches oder Speicherdaten, die z.B. mehrere Container gemeinsam nutzen sollen. </li> </ul> <p>3. Bind Mounts:</p> <ul> <li>Ebenfalls persistent, aber im Gegensatz zu Volumes ist der Speicherort ein echter Ordner auf dem Host-Rechner.</li> </ul> <p>4. tmpfs:</p> <ul> <li>Wird oft als \"tempor\u00e4rer Speicher\" verwendet \u2013 ist aber nicht persistent. Daten bleiben nur im RAM und gehen beim Stopp verloren. Das ist eher f\u00fcr sensible, fl\u00fcchtige Daten (z.B. Passw\u00f6rter) oder Performance-Optimierung geeignet. Darauf sol lerstmal nicht n\u00e4her eingegangen werden.</li> </ul>"},{"location":"content/port_mapping/","title":"Port Mapping in Docker","text":"<p>Container sind in Docker standardm\u00e4\u00dfig isoliert. Das bedeutet: Ein Container startet sein eigenes Netzwerk, kann aber nicht direkt vom Host (z.B. deinem Browser oder Terminal) erreicht werden.   Das ist eine Sicherheitsfunktion \u2013 aber auch ein Problem, wenn man beispielsweise einen Webserver im Container starten m\u00f6chte und von au\u00dfen darauf zugreifen will.</p> <p>Was ist Port Mapping?</p> <p>Port Mapping bedeutet, dass man einen bestimmten Port innerhalb des Containers mit einem Port auf dem Host-Rechner verbindet. Dadurch wird der Container von au\u00dfen \"sichtbar\".   Ein Port ist wie eine T\u00fcr in einem Computer, \u00fcber die Daten ein- oder ausgehen k\u00f6nnen. Man kann sich einen Computer wie ein gro\u00dfes Haus vorstellen \u2013 und jeder Dienst (z.B. ein Webserver, eine Datenbank oder E-Mail) hat seine eigene T\u00fcr, durch die er mit der Au\u00dfenwelt kommuniziert.    In fast allen F\u00e4llen betreibt ein Computer mehrere Programme gleichzeitig. Aber alle Programme verwenden dieselbe IP-Adresse (quasi die Adresse des Hauses). Ports sorgen daf\u00fcr, dass klar ist, welches Programm die Daten bekommen soll.   Bekannte Ports sind z.B.</p> Port Verwendung 80 Webseiten (HTTP) 443 Sichere Webseiten (HTTPS) 22 Fernzugriff \u00fcber SSH 3306 MySQL-Datenbank 6379 Redis-Datenbank"},{"location":"content/port_mapping/#1-beispiel-am-nginx-webderver","title":"1. Beispiel am nginx-Webderver","text":"<p>Nehmen wir an, man m\u00f6chte eine einfache Webseite mit nginx im Container anzeigen lassen. Als erstes hollen wir uns das jeweilige Docker Image:</p> <pre><code>docker pull nginx\n</code></pre> <p>Nun haben wir zwei Docker Images:</p> <p></p> <p>Wir erstellen einen neuen Container, mithilfe dieses Images. Dabei wird der <code>nginx</code>-Server im Container gestartet:</p> <pre><code>docker run nginx\n</code></pre> <p>Im Docker Desktop, sind nun zwei Container vorhanden. Man achte auf den gr\u00fcnen Punkt beim neuen <code>nginx</code>-Container, er bedeutet, dass der Container momentan ausgef\u00fchrt wird. </p> <p></p> <p>Wenn man nun im Browser http://localhost aufruft passiert nichts. Der nginx-Server l\u00e4uft innerhalb des Containers, und zwar auf Port 80. Aber dieser Port ist nur im Container sichtbar \u2013 nicht auf unseren Host-System. Deswegen kann der Browser auf unseren Rechner (also dem Host) diesen Port nicht erreichen, solange man nicht explizit sagt: \"Gib diesen Port nach au\u00dfen frei!\"   Mithilfe von Port Mapping, kann man dieser Problem beseitigen. Wir k\u00f6nnen den Port des Container mit einem Port des Hosts verbinden. Dazu stoppen wir erstmal den Container durch <code>STRG + C</code> oder im Docker Desktop durch das \"Stop\"-Icon:</p> <p></p> <p>Wir f\u00fchren nun nochmal den <code>run</code>-Befehl aus, jedoch verwenden wir den <code>-p</code>-Flag:</p> <pre><code>docker run -p 8080:80 nginx\n</code></pre> <p>Durch diesen Flag, wird der Port 80 im Container (da l\u00e4uft ja nginx drauf) mit dem Port 8080 des Hosts (unser Rechner) verbunden.   Jetzt kann man im Browser http://localhost:8080 aufrufen und die Standardseite von dem <code>nginx</code>-Server wird angezeigt.</p> <p></p> <p>Wenn jemand dem Host auf Port 8080 anspricht, wird er intern weitergeleitet an den Container auf Port 80.</p>"},{"location":"content/runtimes/","title":"Docker Runtimes","text":"<p>Wenn man Container mit Docker ausf\u00fchrt, stellt sich irgendwann die Fragen: </p> <ul> <li> <p>Was passiert im Container \u00fcberhaupt beim Start?</p> </li> <li> <p>Wie wird eigentlich festgelegt, welches Programm gestartet wird?</p> </li> </ul> <p>Hier kommt das Konzept der Runtime ins Spiel \u2013 also der Ablaufumgebung, die bestimmt, was beim Start eines Containers ausgef\u00fchrt wird. Runtimes bezeichnet also die Befehle, die beim Start eines Containers ausgef\u00fchrt werden, um einen laufenden Prozess zu erzeigen wie z.B. einen Webserver, eine Datenbank oder eine Python Anwendung.   Diese Runtime-Konfiguration wird in der Dockerfile festgelegt und kann durch Direktiven gesteuert werden. Eine Direktive in einer Dockerfile ist eine Anweisung, die Docker beim Bauen des Images mitteilt, was zu tun ist. Man kann sich das vorstellen wie eine Rezeptzeile in einer Kochanleitung:</p> <ul> <li> <p>Sie sagt Docker ganz genau, welcher Schritt als N\u00e4chstes ausgef\u00fchrt werden soll \u2013 zum Beispiel:</p> </li> <li> <p>Welche Basis verwendet wird (<code>FROM</code>)</p> </li> <li> <p>Welche Dateien kopiert werden sollen (<code>COPY</code>)</p> </li> <li> <p>Welcher Befehl beim Start des Containers ausgef\u00fchrt werden soll (<code>CMD</code> oder <code>ENTRYPOINT</code>)</p> </li> </ul> <p>Die beiden Direktiven <code>CMD</code> und <code>ENTRYPOINT</code> geben an, welcher Befehl innerhalb des Containers automatisch gestartet werden soll, wenn <code>docker run...</code> ausgef\u00fchrt wird.</p>"},{"location":"content/runtimes/#die-standardausfuhrung-cmd","title":"Die Standardausf\u00fchrung <code>CMD</code>","text":"<p>Die <code>CMD</code>-Direktive legt einen Standardbefehl und ggf. Argumente fest, die beim Start des Containers ausgef\u00fchrt werden sollen \u2013 aber nur dann, wenn beim Aufruf von <code>docker run</code> keine anderen Befehle angegeben werden.   Ein gutes Beispiel ist das offizielle Python-Image, z.B. <code>python:3.12-slim</code>. Dieses Image enth\u00e4lt in der Dockerfile bereits eine CMD-Anweisung:</p> <pre><code>CMD [\"python3\"]\n</code></pre> <p>Man kann den Docker File von <code>python:3.12-slim</code> unter dem folgenden Link erkunden: https://github.com/docker-library/python/blob/a25c9ad64fe168fb619fea7247b17189d441b988/3.12/slim-bookworm/Dockerfile. Vieles davon wird man erstmal nicht verstehen, f\u00fcr uns ist nur wichtig dass da <code>CMD [\"python3\"]</code> vorkommt.  </p> <p>Dabei bedeutet <code>CMD [\"python3\"]</code> dass wenn kein anderer Befehl beim Starten des Containers angegeben wird, dann wird standardm\u00e4\u00dfig python3 ausgef\u00fchrt. Wir sollten also sofort in der Lage sein Python code im Terminal schreiben zu k\u00f6nnen. Wir testen das ganze mit den folgenden Befehl:</p> <pre><code>docker run -it --rm python:3.12-slim\n</code></pre> <ul> <li> <p><code>docker run ...</code> sagt: Starte einen Container aus diesem Image</p> </li> <li> <p><code>it</code> bedeutet: Mach das Terminal interaktiv, damit man tippen kann</p> </li> <li> <p><code>--rm hei\u00dft</code>: L\u00f6sche den Container nach dem Beenden automatisch</p> </li> <li> <p><code>python:3.12-slim</code> ist das Image</p> </li> </ul> <p>Es wird kein weiterer Befehl angegeben, daher greift die CMD [\"python3\"]-Anweisung.</p> <p></p> <p>Was passiert, wenn man einen eigenen Befehl \u00fcbergibt? Nehmen wir z.B.</p> <pre><code>docker run -it --rm python:3.12-slim echo \"Hallo aus Docker\"\n</code></pre> <p>Das Image ist wieder <code>python:3.12-slim</code> aber diesmal \u00fcberschreiben wir die CMD-Anweisung im Docker-File! Docker f\u00fchrt stattdessen den Befehl <code>echo \"Hallo aus Docker\"</code> im Container aus, danach wird der Container beendet und gel\u00f6scht:</p> <p></p> Befehl Verhalten <code>docker run -it --rm python:3.12-slim</code> Startet Python-Interpreter (wegen <code>CMD [\"python3\"]</code>) <code>docker run -it --rm python:3.12-slim echo Hallo</code> Startet nicht Python, sondern f\u00fchrt <code>echo Hallo</code> aus <code>docker run -it --rm nginx</code> Startet den Webserver <code>nginx</code> (weil das dort in <code>CMD</code> steht) <p>Dieses Wissen ist wichtig um:</p> <ul> <li> <p>zu wissen was l\u00e4uft im Container, sobald er gestartet wird?</p> </li> <li> <p>zu verstehen wie man dieses Verhalten beeinflussen oder \u00fcberschreiben kann?</p> </li> <li> <p>eigene Images zu entiwckeln</p> </li> </ul>"},{"location":"content/runtimes/#entrypoint-unveranderlich-beim-start","title":"ENTRYPOINT \u2013 Unver\u00e4nderlich beim Start","text":"<p>Die ENTRYPOINT-Direktive legt fest, welcher Befehl immer beim Start des Containers ausgef\u00fchrt wird \u2013 egal, ob beim <code>docker run</code> zus\u00e4tzliche Befehle angegeben wurden oder nicht. Man kann sich das wie ein fester Startpunkt vorstellen. Im Gegensatz zu CMD wird ENTRYPOINT nicht automatisch ersetzt, sondern:</p> <ul> <li>Der Befehl beim <code>docker run</code> wird als Argument an ENTRYPOINT angeh\u00e4ngt.</li> </ul> <p>Ein sehr gutes Beispiel ist das offizielle <code>nginx-Image</code>. Man kann es wie folgt untersuchen:</p> <pre><code>docker inspect nginx\n</code></pre> <p>In der Ausgabe findet man unter <code>Entrypoint</code> den Eintrag: <code>\"/docker-entrypoint.sh\"</code></p> <p></p> <p>Der ENTRYPOINT ist das Shell-Skript <code>/docker-entrypoint.sh</code>. Es wird immer ausgef\u00fchrt, sobald ein Container aus diesem Image gestartet wird. Der CMD enth\u00e4lt den Standardbefehl <code>nginx -g 'daemon off;'</code>, also den Start des Webservers im Vordergrund-Modus (daemon off = bleibe im Vordergrund, wichtig f\u00fcr Docker).</p> <p>Szenario 1: Container ganz normal starten:</p> <p>Durch </p> <pre><code>docker run --rm nginx\n</code></pre> <p>kombiniert Docker automatisch ENTRYPOINT und CMD. Intern f\u00fchrt Docker folgendes aus:</p> <pre><code>/docker-entrypoint.sh nginx -g 'daemon off;'\n</code></pre> <p>Szenario 2: Eigenen Befehl \u00fcbergeben:</p> <pre><code>docker run --rm nginx echo \"Hallo ENTRYPOINT\"\n</code></pre> <p>Hier sieht man deutlich den Unterschied zu CMD:</p> <ul> <li> <p>Das ENTRYPOINT-Skript bleibt erhalten.</p> </li> <li> <p>Der neue Befehl echo ersetzt nicht das ENTRYPOINT, sondern wird als Argument an das Skript \u00fcbergeben.</p> </li> </ul>"},{"location":"content/runtimes/#ubuntu-desktop-in-docker-mit-grafischer-oberflach","title":"Ubuntu-Desktop in Docker mit grafischer Oberfl\u00e4ch","text":"<p>Wenn man mit Docker arbeitet, sind die meisten Container rein textbasiert \u2013 man arbeitet also \u00fcber die Kommandozeile, z.B. mit <code>bash</code>, <code>sh</code>, <code>python</code>, usw. Aber was, wenn man einmal eine grafische Benutzeroberfl\u00e4che (GUI) sehen m\u00f6chte \u2013 wie man es von einem normalen Desktop-Betriebssystem kennt?   Wir laden als erstes ein spezielles Ubunto-Image. Dieses Image basiert auf Ubuntu und bringt eine vollst\u00e4ndige grafische Desktop-Oberfl\u00e4che (LXDE) mit, die per VNC \u00fcber den Browser erreichbar gemacht wird:</p> <pre><code>dorowu/ubuntu-desktop-lxde-vnc\n</code></pre> <p>Wir starten den Container:</p> <pre><code>docker run -d -p 6080:80 --name ubuntu-desktop dorowu/ubuntu-desktop-lxde-vnc\n</code></pre> <p>Sobald der Container l\u00e4uft, kann man im Browser folgende Adresse aufrufen:</p> <pre><code>http://localhost:6080\n</code></pre> <p>Nun erscheint eine vollst\u00e4ndige grafische Desktop-Oberfl\u00e4che von Ubuntu:</p> <p></p> <p>ie grafische Oberfl\u00e4che l\u00e4uft komplett im Container, und der Browser stellt nur die Benutzeroberfl\u00e4che dar \u2013 ganz ohne zus\u00e4tzliche Software auf dem Host. Die Anwendungsm\u00f6glichkeiten sind sehr vielf\u00e4ltig:</p> <ul> <li> <p>F\u00fcr Lernzwecke, um Ubuntu grafisch zu erkunden</p> </li> <li> <p>Zum Testen von GUI-Tools unter Linux</p> </li> <li> <p>Um grafische Entwicklungsumgebungen (z.\u202fB. VSCode, Gedit) auszuf\u00fchren</p> </li> </ul> <p>Das Image <code>dorowu/ubuntu-desktop-lxde-vnc</code> verwendet einen ENTRYPOINT, der den VNC-Server und die grafische Umgebung startet. Dieser ENTRYPOINT bleibt wie wir bereits kennen gelernt haben immer aktiv, auch wenn man \u00fcber ein CMD versucht, etwas anderes auszuf\u00fchren.</p> <p>Wir k\u00f6nnne \u00fcber <code>docker inspect ubuntu-desktop dorowu/ubuntu-desktop-lxde-vnc</code> den ENTRYPOINT untersuchen. Dabei findet man den folgenden Eintrag:</p> <p></p> <p>Das bedeutet: Bei jedem Start wird <code>/startup.sh</code> ausgef\u00fchrt \u2013 das Skript startet den grafischen Desktop.</p>"},{"location":"content/runtimes/#fazit","title":"Fazit","text":"<p>Die Kombination von ENTRYPOINT + CMD erlaubt es, das Containerverhalten intelligent zu steuern:</p> Kombination Wirkung <code>ENTRYPOINT</code> fest + <code>CMD</code> flexibel Standardverhalten, aber bei Bedarf anpassbar Nur <code>CMD</code> Leicht zu \u00fcberschreiben, weniger Kontrolle Nur <code>ENTRYPOINT</code> Fixes Verhalten, keine flexible Argumente m\u00f6glich Beide kombiniert Maximale Flexibilit\u00e4t mit festem Einstiegspunkt <p>Das ist besonders hilfreich bei Containern, die:</p> <ul> <li> <p>beim Start Setups oder Pr\u00fcfungen durchf\u00fchren m\u00fcssen,</p> </li> <li> <p>unterschiedliche Modi (z.B. Test, Debug, Produktion) starten sollen,</p> </li> <li> <p>oder eine eigene Befehlssprache anbieten.</p> </li> </ul> <p>Als Merksatz kann man aus dem Kapitel folgendes mitnehmen:</p> <ul> <li> <p>ENTRYPOINT = Was immer ausgef\u00fchrt wird</p> </li> <li> <p>CMD = Was standardm\u00e4\u00dfig \u00fcbergeben wird (optional)</p> </li> </ul>"},{"location":"content/slim_alpine_images/","title":"Slim- und Alpine-Images: Kleine, schnelle Docker-Container","text":"<p>Wenn man Docker-Container erstellt oder verwendet, st\u00f6\u00dft man schnell auf ein zentrales Thema: die Gr\u00f6\u00dfe der Docker-Images. Ein typisches Image wie z.B. python kann \u00fcber 1 GB gro\u00df sein. Das bedeutet:</p> <ul> <li> <p>Langes Herunterladen</p> </li> <li> <p>L\u00e4ngeres Starten</p> </li> <li> <p>H\u00f6herer Speicherbedarf</p> </li> <li> <p>Mehr Daten, die \u00fcber das Netzwerk \u00fcbertragen werden m\u00fcssen (z.B. beim Deployment)</p> </li> </ul> <p>In vielen F\u00e4llen braucht man aber gar nicht das komplette Betriebssystem oder eine voll ausgestattete Entwicklungsumgebung. F\u00fcr viele Anwendungen reichen minimale Laufzeitumgebungen v\u00f6llig aus \u2013 und genau daf\u00fcr gibt es Slim- und Alpine-Images.</p>"},{"location":"content/slim_alpine_images/#was-sind-slim-images","title":"Was sind Slim-Images?","text":"<p>Slim-Images sind speziell optimierte Versionen von Basis-Images wie <code>python</code>, <code>node</code>, <code>debian</code> oder <code>ubuntu</code>. Sie enthalten nur die notwendigsten Bestandteile des Betriebssystems und der Umgebung, um eine bestimmte Anwendung auszuf\u00fchren.</p> <p></p> <p>Das Docker Image welches Python in Version 3.13 enth\u00e4lt basiert auf einem vollst\u00e4ndigen Debian/Linux-System. Es enth\u00e4lt</p> <ul> <li> <p>Die offizielle Version von Python</p> </li> <li> <p>Systembibliotheken, also alles notwendige damit Python funktioniert</p> </li> <li> <p>Den Paketmanager <code>apt</code> um weitere Tools wie z.B. Git zu installieren</p> </li> <li> <p>Die Shell als interaktive Kommandozeile im Container</p> </li> <li> <p>Au\u00dferdem grundlegende Tools wie z.B. <code>pip</code>, <code>ls</code>, <code>echo</code> und mehr</p> </li> </ul> <p>Man kann sich dieses Image als eine kleine virtuelle Linux-Maschine vorstellen, welches alles was man zur Python-Programmierung ben\u00f6tigt, enth\u00e4lt. Wir laden als erstes dieses Image herunter:</p> <pre><code>docker pull python:3.12\n</code></pre> <p>Nun hat man auch die M\u00f6glichkeit eine \"verschlankte\" Variante des offiziellen Python-Images herunterzuladen. Es ent\u00e4lt ebenfalls die Python 3.12 Version, basiert auf Debian, welches allerdings eine stark reduzierte Version ist. Bei dem Debian-System wurden viele nicht ben\u00f6tigte Pakete und Tools entfernt. Ziel ist es das Image so klein wie m\u00f6glich zu machen, aber Python trotzdem vollst\u00e4ndig lauff\u00e4hig zu halten.   Wir laden nun diese \"verschlankte\" Version herunter:</p> <pre><code>docker pull python:3.12-slim\n</code></pre> <p>Nun k\u00f6nnen wir die Speicherkapizit\u00e4t vergleichen:</p> <pre><code>docker image ls\n</code></pre> <p></p> <p>Man sieht deutlich, dass die <code>slim</code>-Variante, etwa um den Faktor 10 kleiner ist.</p> <p>Beide Image Varianten haben ihre Vor- und Nachteile. Die <code>slim</code>-Variante hat:</p> <ul> <li> <p>Weniger vorinstallierte Tools, Tools wie z.B. <code>curl</code>, <code>git</code> sind nicht enthalten.</p> </li> <li> <p>Fehlende Systembibliotheken, welche f\u00fcr manche Python-Module ben\u00f6tigt werdem</p> </li> <li> <p>Weniger Tools f\u00fcr das Debugging</p> </li> </ul> <p>Solche <code>slim</code>-Varianten verwendet man f\u00fcr Produktivumgebungen, bei denen jede Megabyte z\u00e4hlt. In der Cloud kosten Speicherplatz, Netzwerkverkehr und Startzeiten Geld. Je kleiner ein Container-Image ist, desto weniger Daten m\u00fcssen \u00fcber das Netz (z.B. AWS, Azure, GCP) \u00fcbertragen werden. In modernen Softwareprojekten wird Code st\u00e4ndig automatisch getestet, gebaut und ausgeliefert mit sogenannten CI/CD-Pipelines. Dabei m\u00fcssen Container schnell starten und die Zeiten minimal halten, um die Pipeline nicht zu verz\u00f6gern. In einer GitHub Actions Pipeline wird bei jedem Commit ein neuer Container gebaut und getestet. Ein kleineres Basis-Image bedeutet schnelleres Feedback f\u00fcr Entwickler und weniger Rechenkosten.</p>"},{"location":"content/slim_alpine_images/#was-sind-alpine-images","title":"Was sind Alpine-Images?","text":"<p>Alpine Linux ist eine speziell entwickelte, extrem schlanke Linux-Distribution, die f\u00fcr Sicherheit, Minimalismus und Gr\u00f6\u00dfe optimiert wurde. Die gesamte Grundinstallation ist nur ca. 50\u202fMB gro\u00df \u2013 verglichen mit hunderten Megabytes bei traditionellen Distributionen wie Debian oder Ubuntu.   Docker bietet viele offizielle Images auf Basis von Alpine an, z.B.:</p> <ul> <li> <p>python:3.12-alpine</p> </li> <li> <p>node:20-alpine</p> </li> <li> <p>nginx:alpine</p> </li> </ul> <p></p> <p>Diese Images sind ebenfalls so konzipiert, dass sie nur das N\u00f6tigste enthalten, was ein Container zum Starten braucht. Alpine ist nicht nur \"klein\" \u2013 es ist auch fundamental anders aufgebaut als die meisten bekannten Linux-Distributionen wie z.B. Debian, auf denen die meisten Docker-Images (z.B. slim) basieren.   Diese Unterschiede betreffen wichtige Systemkomponenten wie die C-Bibliothek, die Shell oder den Paketmanager \u2013 und genau das kann bei der Entwicklung oder Verwendung von Software zu Problemen f\u00fchren. Die Entscheidung f\u00fcr Alpine bedeutet: Man arbeitet nicht mit einem typischen Linux, wie man es von Servern, Cloud-Umgebungen oder dem eigenen Rechner kennt. Alpine verwendet z.B. ash, eine reduzierte Version der Shell, die deutlich weniger Features hat als bash. Viele Skripte, die unter bash funktionieren, scheitern in Alpine.   Wie laden uns mal das <code>alpine</code>-Image von Python:</p> <pre><code>docker pull python:3.12-alpine\n</code></pre> <p>Und vergleichen nochmals die Speicherkapazit\u00e4t:</p> <pre><code>docker images ls\n</code></pre> <p></p> <p>Die <code>alpine</code>-Images werden verwendet wenn:</p> <ul> <li> <p>Das kleinste Image was es gibt ben\u00f6tigt wird f\u00fcr z.B. produktiv-Anwendungen (h\u00e4ufig in der Cloud).</p> </li> <li> <p>Wenn man die Angriffsfl\u00e4che minimieren m\u00f6chte. Durch die wenigen Tools sind weniger potenzielle Sicherheitsl\u00fccken vorhanden.</p> </li> <li> <p>Die Container nur wenige Abh\u00e4ngigkeiten ben\u00f6tigen, z.B. nur einfache <code>curl</code>-Befehle</p> </li> <li> <p>Die <code>alpine</code>-Images laden und starten am schnellsten, ideal f\u00fcr Pipelines</p> </li> </ul> <p>Man sollte aber immer beachten, das mehr Aufwand bei der Konfiguration der <code>alpine</code>-Images betrieben wird. Oft muss man bestimmte Tools nachinstallieren und bestimmte passende Pakete f\u00fcr sein Vorhaben finden. Wenn man also schnell los legen m\u00f6chte sollte man <code>slim</code>-Images verwenden. Wenn es jedoch sehr minimal sein soll, verwendet mal <code>alpine</code>-Images.</p>"},{"location":"content/tagging/","title":"Tagging von Docker-Images","text":"<p>Wenn man mit Docker arbeitet, kommt man sehr schnell mit dem Konzept der Tags in Ber\u00fchrung. Ein Tag ist im Kontext von Docker eine Bezeichnung (ein Label), die einer bestimmten Version eines Docker-Images zugewiesen wird. Man kann es sich vorstellen wie ein Versionsstempel, z.B. <code>nginx:1.27</code>. Die Syntax allgemein formuliert, lautet:</p> <pre><code>repository:tag\n</code></pre> <p>Jedes Mal, wenn der Befehl <code>docker run nginx</code> ausgef\u00fchrt wurde, verwendete Docker entweder die neueste verf\u00fcgbare Version des Images oder griff auf eine bereits lokal vorhandene Version zur\u00fcck. Wenn wir nun den Tag verwenden, k\u00f6nnen wir eine bestimmte Version des Docker-Images verwenden:</p> <pre><code>docker run nginx:1.27\n</code></pre> <p></p> <p>Auch in Docker Desktop wird diese Version unter \"Images\" angezeigt:</p> <p></p> <p>Vorsicht beim Verwenden von <code>latest</code>:</p> <p>Wenn man mit Docker arbeitet und z.B. den Befehl <code>docker run nginx</code> ausf\u00fchrt, ohne eine bestimmte Version anzugeben, wird standardm\u00e4\u00dfig das Image mit dem Tag <code>latest</code> verwendet. Auf den ersten Blick klingt das bequem: Man erh\u00e4lt scheinbar immer die \"aktuellste\" Version. Doch genau hier liegt ein verbreitetes Missverst\u00e4ndnis und eine potenzielle Fehlerquelle \u2013 vor allem in produktiven Umgebungen.  </p> <p>Der Tag <code>latest</code> ist kein technisches Konzept, das automatisch immer auf die neueste verf\u00fcgbare Version eines Images zeigt. Stattdessen ist <code>latest</code> ein ganz normaler Tag-Name, der von den Image-Autoren (bzw. vom Team, das die Images verwaltet) manuell vergeben wird \u2013 genau wie jeder andere Tag, z.B. <code>1.27.0</code>, <code>alpine</code>, <code>slim</code> oder <code>python3.12</code>.  </p> <p>Man kann sich das wie ein Symbolischen Link (alias) vorstellen, der auf ein bestimmtes Image verweist. Das bedeutet aber auch: Der Inhalt hinter dem Tag <code>latest</code> kann sich jederzeit \u00e4ndern!  </p> <p>Angenommen, heute zeigt <code>nginx:latest</code> auf die Version <code>1.27.0</code>. Das hei\u00dft, wenn man das Image jetzt mit <code>docker pull nginx</code> l\u00e4dt, erh\u00e4lt man genau diese Version. Einige Tage sp\u00e4ter ver\u00f6ffentlichen die Maintainer jedoch die Version <code>1.28.0</code> und aktualisieren den <code>latest</code>-Tag, sodass dieser nun auf <code>1.28.0</code> zeigt. Wenn man nun erneut <code>docker pull nginx</code> ausf\u00fchrt oder ein neues Image baut, das auf <code>nginx:latest</code> basiert, erh\u00e4lt man eine andere Version als zuvor \u2013 ohne es vielleicht zu merken.</p> <p></p> <p>Wenn sich die Version eines Images stillschweigend \u00e4ndert, kann das:</p> <ul> <li> <p>zu unterschiedlichem Verhalten der Anwendung f\u00fchren,</p> </li> <li> <p>Fehler verursachen, die sich schwer debuggen lassen,</p> </li> <li> <p>oder im schlimmsten Fall sogar den Betrieb st\u00f6ren.</p> </li> </ul> <p>Statt <code>latest</code> zu verwenden, sollte man in der Praxis immer eine explizite, feste Version angeben, z.B.:</p> <pre><code>docker run nginx:1.27.0-bookworm\n</code></pre> <p>Der Digest-Pinning:</p> <p>In Docker werden Images in sogenannten Image-Registries gespeichert (z.B. Docker Hub):</p> <p></p> <p>Beim Herunterladen eines Images \u2013 etwa mit <code>docker pull nginx:1.27</code> \u2013 l\u00e4dt Docker ein bestimmtes Image aus dieser Registry. Dieser Zugriff erfolgt standardm\u00e4\u00dfig \u00fcber einen Tag wie <code>1.27</code>, <code>latest</code> oder <code>alpine</code>. Wir haben gesehen das ein Tag ver\u00e4nderbar ist. Ein Tag wie <code>nginx:1.27</code> kann heute auf ein bestimmtes Image in der Registry zeigen und morgen auf ein anderes.   Wenn man jedoch ein Image \u00fcber seinen Digest anfordert, verwendet Docker eine exakte, nicht ver\u00e4nderbare Version des Images. Ein Digest ist ein SHA256-Hash, der den vollst\u00e4ndigen Zustand eines Images beschreibt. Solche Hashes garantieren, dass der Inhalt des Images exakt derselbe bleibt \u2013 selbst \u00fcber Jahre hinweg.   Um den Digest (SHA256-Hash) eines bereits heruntergeladenen Images anzuzeigen, kann man folgenden Befehl verwenden:</p> <pre><code>docker image ls --digests\n</code></pre> <p></p> <p>Man kann sich auch einen guten \u00dcberblick \u00fcber die Digests, auf der UI von Docker Desktop bzw. Docker Hub, verschaffen:</p> <p></p> <p>Im Web-Browser kann durch den Link https://hub.docker.com/_/nginx/tags die <code>ngnix</code>-Seite auf Dockerhub aufrufen. Da hat man die M\u00f6glichkeit auf die angezeigten Zahlen, bei der \"Digest\" Spalte, anzuklicken:</p> <p></p> <p>Dann kann man sich die exakte Digest des jeweiligen Images ansehen und falls notwendig kopieren:</p> <p></p> <p>Nun kann man die exakte Version des Images downloaden, indem man die Digest angibt. Wie bereits gesagt, der Tag kann pl\u00f6tzlich auf ein anderes Image zeigen, die Digest jedoch nicht:</p> <pre><code>docker run -p 8080:80 nginx@sha256:bbb494fb3812686ad46acb3b81025a8a51f89394164ee9fd33faea0ce37eb394\n</code></pre> <p></p>"},{"location":"content/tagging/#fazit","title":"Fazit","text":"<p>Beim Arbeiten mit Docker-Images sind Tags ein zentrales Werkzeug, um die gew\u00fcnschte Version eines Images zu bestimmen. Doch hinter ihrer scheinbaren Einfachheit verbergen sich wichtige \u00dcberlegungen:</p> <ul> <li> <p><code>latest</code> ist kein verl\u00e4sslicher Zeiger auf die \"neueste\" Version \u2013 es ist nur ein Name, der sich jederzeit \u00e4ndern kann.</p> </li> <li> <p>Feste Versionstags wie <code>nginx:1.27.0</code> sorgen f\u00fcr mehr Stabilit\u00e4t, da sie gezielt auf bestimmte Releases zeigen.</p> </li> <li> <p>Digest-Pinning (@sha256:...) ist die zuverl\u00e4ssigste Methode, um ein Image eindeutig zu referenzieren. So wird sichergestellt, dass in Entwicklung, Test und Produktion exakt das gleiche Image verwendet wird \u2013 selbst wenn sich Tags oder Inhalte auf dem Registry-Server \u00e4ndern.</p> </li> </ul> <p>In produktiven Umgebungen ist es daher unerl\u00e4sslich, auf Digest-Pinning zu setzen oder zumindest exakt versionierte Tags zu verwenden. Dies sch\u00fctzt vor unerwarteten \u00c4nderungen und sorgt f\u00fcr konsistente, reproduzierbare Builds.</p>"},{"location":"content/uebung_1/","title":"1. \u00dcbung","text":"<p>In dieser \u00dcbung sammelst du erste praktische Erfahrungen mit Docker und vertiefst zentrale Begriffe.</p> 1. \u00dcbung \u2014 Aufgabe 1 <p>Erkl\u00e4re die folgenden Begriffe in eigenen Worten:</p> <ul> <li> <p>Docker Image</p> </li> <li> <p>Docker Container</p> </li> <li> <p>Dockerfile</p> </li> </ul> 1. \u00dcbung \u2014 Aufgabe 2 <p>F\u00fchre die folgenden Befehle im Terminal aus und beschreibe, was sie jeweils tun:</p> <pre><code>docker pull hello-world\ndocker run hello-world\ndocker image ls\ndocker ps -a\n</code></pre> <p>Beantworte danach:</p> <ul> <li> <p>Wie viele Images und wie viele Container siehst du?</p> </li> <li> <p>Welche Unterschiede fallen dir bei <code>docker image ls</code> vs. <code>docker ps -a</code> auf?</p> </li> </ul> 1. \u00dcbung \u2014 Aufgabe 3 <p>Beschreibe mit eigenen Worten, warum es sinnvoll ist, in Docker zwischen Images und Containern zu unterscheiden. Welche Vorteile bringt diese Trennung im Vergleich zu klassischen Installationen?</p> 1. \u00dcbung \u2014 Aufgabe 4 <ol> <li> <p>Erkl\u00e4re mit eigenen Worten, was Docker ist und wof\u00fcr es verwendet wird.</p> </li> <li> <p>Warum verwendet man Container in der Softwareentwicklung? Nenne mindestens drei Vorteile von Containern gegen\u00fcber klassischer Softwareinstallation.</p> </li> <li> <p>Warum verwendet man Container in der Softwareentwicklung? Nenne mindestens drei Vorteile von Containern gegen\u00fcber klassischer Softwareinstallation.</p> </li> <li> <p>Welche Rolle spielt das Dockerfile? Was beschreibt es?</p> </li> <li> <p>Was versteht man unter dem Begriff \"Port-Mapping\" in Docker?</p> </li> <li> <p>Was passiert beim Befehl <code>docker pull nginx</code>?</p> </li> <li> <p>Wie kann man alle laufenden Container anzeigen? Wie auch gestoppte?</p> </li> <li> <p>Was passiert, wenn man versucht, denselben Container mit <code>docker run</code> erneut zu starten?</p> </li> <li> <p>Wie kann man einen gestoppten Container l\u00f6schen?</p> </li> </ol> 1. \u00dcbung \u2014 Aufgabe 5 <p>Was bewirkt der folgende Befehl:</p> <pre><code>docker run -d -p 8080:80 nginx\n</code></pre> <p>Erkl\u00e4re die Bedeutung der einzelnen Optionen.</p> 1. \u00dcbung \u2014 Aufgabe 6 <ol> <li> <p>Was unterscheidet Docker von einer klassischen virtuellen Maschine (VM)?</p> </li> <li> <p>Wie hilft Docker in einem Entwicklerteam mit unterschiedlichen Betriebssystemen?</p> </li> <li> <p>Wie stellt Docker sicher, dass eine Anwendung \u00fcberall gleich funktioniert?</p> </li> <li> <p>Was sind potenzielle Herausforderungen oder Risiken bei der Arbeit mit Docker?</p> </li> <li> <p>Wann ist es sinnvoll, ein eigenes Image zu erstellen statt ein fertiges zu verwenden?</p> </li> </ol> 1. \u00dcbung \u2014 Aufgabe 7 <p>Ordne den Begriff der richtigen Bedeutung zu:</p> Begriff Bedeutung <code>docker ps</code> A. Zeigt laufende Container <code>docker build</code> B. Erstellt ein Image aus einem Dockerfile <code>docker rm</code> C. L\u00f6scht einen Container <code>docker image ls</code> D. Zeigt vorhandene Images <code>docker run</code> E. Startet einen neuen Container aus einem Image 1. \u00dcbung \u2014 Aufgabe 8 <p>Beantworte folgende Fragen:</p> <ol> <li> <p>Was ist ein Tag in Docker und wof\u00fcr wird er verwendet?</p> </li> <li> <p>Wie sieht die allgemeine Syntax eines Docker-Images mit Tag aus? Gib ein Beispiel.</p> </li> <li> <p>Was passiert, wenn man ein Image ohne Tag startet, z.B. <code>docker run nginx</code>?</p> </li> <li> <p>Warum ist der Tag <code>latest</code> problematisch in produktiven Umgebungen?</p> </li> <li> <p>Was versteht man unter \"Digest-Pinning\"?</p> </li> <li> <p>Wie unterscheidet sich der Digest von einem Tag?</p> </li> <li> <p>Welche Vorteile bietet es, feste Versions-Tags z.B. <code>python:3.11</code> zu verwenden?</p> </li> <li> <p>Ein Update des Images <code>node:latest</code> hat deinen Code pl\u00f6tzlich funktionsunf\u00e4hig gemacht. Was h\u00e4tte man im Voraus tun k\u00f6nnen, um das zu vermeiden?</p> </li> </ol>"}]}